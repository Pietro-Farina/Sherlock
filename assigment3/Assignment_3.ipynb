{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfSY0aRljLxW"
   },
   "source": [
    "## Assigment 3\n",
    "\n",
    "### Authors: Jacopo Corrao, Pietro Farina\n",
    "\n",
    "This assignment consist in developing code that combines LLMs and traditional ML to extract knowledge from the Openreivew review dataset.\n",
    "The goal is to find interesting patterns in reviews (and possibly, why not, in papers) that can give hints to authors about how to write better papers.\n",
    "\n",
    "\n",
    "We deciced to organize the work in the following:\n",
    "\n",
    "1. Manual inspection of the dataset\n",
    "2. Data Cleaning\n",
    "3. Knowledge Extraction from Paper Acceptance Data using BERT-based NLP Techniques\n",
    "4. Paper Acceptance Analysis\n",
    "5. Pairwise comparison of papers through LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sqoIQcoopYG"
   },
   "source": [
    "### Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pPg4-_PzoT92"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "my_secret_key = userdata.get('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAtQXNuCo83V",
    "outputId": "77fce77d-832a-4537-c4ed-b7bde10fc12e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7C3ZlUzopAdx",
    "outputId": "bf93961a-837b-4b8a-f9b4-60877c5e7be3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "file_path = \"/content/drive/MyDrive/KnowledgeDiscoveryAndPatternExtraction/open_review_dataset.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2XE1z7flXYO"
   },
   "source": [
    "\n",
    "# Manual Inspection of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yrkrDYAooxBR",
    "outputId": "023cbeb8-1c77-4972-80f1-64ffd9c0b633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sheet1', 'Sheet2', 'Sheet3', 'Sheet4', 'Sheet6', 'Sheet5']\n",
      "{'columns': ['title', 'Unnamed: 1', 'keywords', 'E', 'F', 'G', 'decision', 'J', 'K', 'rate', 'T'], 'head': [{'title': '#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning | OpenReview', 'Unnamed: 1': '06 Nov 2016 (modified: 10 Jan 2017)', 'keywords': 'Keywords:###Deep learning, Reinforcement Learning, Games', 'E': 'Conflicts:###berkeley.edu, eecs.berkeley.edu, openai.com, ugent.be', 'F': 93, 'G': '06 Feb 2017', 'decision': 'Decision:###Reject', 'J': 1458, 'K': '22 Dec 2016 10 Jan 2017', 'rate': 4, 'T': 1655}, {'title': '#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning | OpenReview', 'Unnamed: 1': '06 Nov 2016 (modified: 10 Jan 2017)', 'keywords': 'Keywords:###Deep learning, Reinforcement Learning, Games', 'E': 'Conflicts:###berkeley.edu, eecs.berkeley.edu, openai.com, ugent.be', 'F': 93, 'G': '06 Feb 2017', 'decision': 'Decision:###Reject', 'J': 1458, 'K': '19 Dec 2016 (modified: 24 Jan 2017) 10 Jan 2017 24 Jan 2017', 'rate': 6, 'T': 4910}, {'title': '#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning | OpenReview', 'Unnamed: 1': '06 Nov 2016 (modified: 10 Jan 2017)', 'keywords': 'Keywords:###Deep learning, Reinforcement Learning, Games', 'E': 'Conflicts:###berkeley.edu, eecs.berkeley.edu, openai.com, ugent.be', 'F': 93, 'G': '06 Feb 2017', 'decision': 'Decision:###Reject', 'J': 1458, 'K': '17 Dec 2016 10 Jan 2017', 'rate': 7, 'T': 1427}, {'title': 'A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks | OpenReview', 'Unnamed: 1': '05 Nov 2016 (modified: 29 Nov 2018)', 'keywords': 'Keywords:###Computer vision', 'E': 'Conflicts:###uchicago.edu, ttic.edu', 'F': 103, 'G': '06 Feb 2017', 'decision': 'Decision:###Accept (Poster)', 'J': 274, 'K': '20 Dec 2016 14 Jan 2017', 'rate': 6, 'T': 273}, {'title': 'A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks | OpenReview', 'Unnamed: 1': '05 Nov 2016 (modified: 29 Nov 2018)', 'keywords': 'Keywords:###Computer vision', 'E': 'Conflicts:###uchicago.edu, ttic.edu', 'F': 103, 'G': '06 Feb 2017', 'decision': 'Decision:###Accept (Poster)', 'J': 274, 'K': '20 Dec 2016 (modified: 20 Dec 2016) 14 Jan 2017', 'rate': 6, 'T': 1575}]}\n",
      "{'columns': ['序号', 'title', 'rate', 'reviewLength', 'decision', 'avgscore'], 'head': [{'序号': 1025, 'title': '“Style” Transfer for Musical Audio Using Multiple Time-Frequency Representations | OpenReview', 'rate': 7, 'reviewLength': 4071, 'decision': 'Decision:###Reject', 'avgscore': nan}, {'序号': 1026, 'title': '“Style” Transfer for Musical Audio Using Multiple Time-Frequency Representations | OpenReview', 'rate': 6, 'reviewLength': 4451, 'decision': 'Decision:###Reject', 'avgscore': nan}, {'序号': 1027, 'title': '“Style” Transfer for Musical Audio Using Multiple Time-Frequency Representations | OpenReview', 'rate': 4, 'reviewLength': 5481, 'decision': 'Decision:###Reject', 'avgscore': nan}, {'序号': 2522, 'title': '3C-GAN: AN CONDITION-CONTEXT-COMPOSITE GENERATIVE ADVERSARIAL NETWORKS FOR GENERATING IMAGES SEPARATELY | OpenReview', 'rate': 4, 'reviewLength': 1261, 'decision': 'Decision:###Reject', 'avgscore': nan}, {'序号': 2523, 'title': '3C-GAN: AN CONDITION-CONTEXT-COMPOSITE GENERATIVE ADVERSARIAL NETWORKS FOR GENERATING IMAGES SEPARATELY | OpenReview', 'rate': 4, 'reviewLength': 5867, 'decision': 'Decision:###Reject', 'avgscore': nan}]}\n",
      "{'columns': ['title', 'submit_date', 'decision', 'rate', 'keywords'], 'head': [{'title': '$A^*$ sampling with probability matching | OpenReview', 'submit_date': '28 Sep 2018 (modified: 21 Dec 2018)', 'decision': 'Reject', 'rate': 6, 'keywords': nan}, {'title': '$A^*$ sampling with probability matching | OpenReview', 'submit_date': '28 Sep 2018 (modified: 21 Dec 2018)', 'decision': 'Reject', 'rate': 3, 'keywords': nan}, {'title': '$A^*$ sampling with probability matching | OpenReview', 'submit_date': '28 Sep 2018 (modified: 21 Dec 2018)', 'decision': 'Reject', 'rate': 5, 'keywords': nan}, {'title': '(Unconstrained) Beam Search is Sensitive to Large Search Discrepancies | OpenReview', 'submit_date': '28 Sep 2018 (modified: 21 Dec 2018)', 'decision': 'Reject', 'rate': 5, 'keywords': 'Keywords:###beam search, sequence models, search, sequence to sequence'}, {'title': '(Unconstrained) Beam Search is Sensitive to Large Search Discrepancies | OpenReview', 'submit_date': '28 Sep 2018 (modified: 21 Dec 2018)', 'decision': 'Reject', 'rate': 7, 'keywords': 'Keywords:###beam search, sequence models, search, sequence to sequence'}]}\n",
      "{'columns': ['title', 'publish_time', 'keywords', 'tL_DL', 'paper_decision_time', 'decision', 'paper_decision_commentlength', 'review_publish_time', 'rate', 'review_score_one', 'review_score_two', 'review_score_three', 'review_contentlength'], 'head': [{'title': '{COMPANYNAME}11K: An Unsupervised Representation Learning Dataset for Arrhythmia Subtype Discovery | OpenReview', 'publish_time': '26 Sep 2019 (modified: 20 Dec 2019)', 'keywords': 'Keywords:###representation learning, healthcare, medical, clinical, dataset, ecg, cardiology, heart, discovery, anomaly detection, out of distribution', 'tL_DL': 'TL;DR:###We release a dataset constructed from single-lead ECG data from 11,000 patients who were prescribed to use the {DEVICENAME}(TM) device.', 'paper_decision_time': '20 Dec 2019 (modified: 20 Dec 2019)', 'decision': 'Reject', 'paper_decision_commentlength': 297, 'review_publish_time': '22 Oct 2019 (modified: 06 Nov 2019) 13 Nov 2019 (modified: 15 Nov 2019)', 'rate': 3, 'review_score_one': 'Review Assessment: Thoroughness In Paper Reading:###I read the paper at least twice and used my best judgement in assessing the paper.', 'review_score_two': 'Review Assessment: Checking Correctness Of Experiments:###N/A', 'review_score_three': 'Review Assessment: Checking Correctness Of Derivations And Theory:###N/A', 'review_contentlength': 1766}, {'title': '{COMPANYNAME}11K: An Unsupervised Representation Learning Dataset for Arrhythmia Subtype Discovery | OpenReview', 'publish_time': '26 Sep 2019 (modified: 20 Dec 2019)', 'keywords': 'Keywords:###representation learning, healthcare, medical, clinical, dataset, ecg, cardiology, heart, discovery, anomaly detection, out of distribution', 'tL_DL': 'TL;DR:###We release a dataset constructed from single-lead ECG data from 11,000 patients who were prescribed to use the {DEVICENAME}(TM) device.', 'paper_decision_time': '20 Dec 2019 (modified: 20 Dec 2019)', 'decision': 'Reject', 'paper_decision_commentlength': 297, 'review_publish_time': '22 Oct 2019 (modified: 15 Nov 2019) 13 Nov 2019', 'rate': 3, 'review_score_one': 'Review Assessment: Thoroughness In Paper Reading:###I read the paper thoroughly.', 'review_score_two': 'Review Assessment: Checking Correctness Of Experiments:###I carefully checked the experiments.', 'review_score_three': 'Review Assessment: Checking Correctness Of Derivations And Theory:###I assessed the sensibility of the derivations and theory.', 'review_contentlength': 4246}, {'title': '3D-SIC: 3D Semantic Instance Completion for RGB-D Scans | OpenReview', 'publish_time': '26 Sep 2019 (modified: 28 Nov 2019)', 'keywords': 'Keywords:###3d reconstruction, rgb-d scanning, 3d learning, 3d scene understanding', 'tL_DL': 'TL;DR:###From an incomplete RGB-D scan of a scene, we aim to detect the individual object instances comprising the scene and infer their complete object geometry.', 'paper_decision_time': '08 Nov 2019', 'decision': 'Reject', 'paper_decision_commentlength': 0, 'review_publish_time': '05 Nov 2019 (modified: 06 Nov 2019)', 'rate': 3, 'review_score_one': 'Review Assessment: Thoroughness In Paper Reading:###I read the paper at least twice and used my best judgement in assessing the paper.', 'review_score_two': 'Review Assessment: Checking Correctness Of Experiments:###I did not assess the experiments.', 'review_score_three': 'Review Assessment: Checking Correctness Of Derivations And Theory:###N/A', 'review_contentlength': 2850}, {'title': '3D-SIC: 3D Semantic Instance Completion for RGB-D Scans | OpenReview', 'publish_time': '26 Sep 2019 (modified: 28 Nov 2019)', 'keywords': 'Keywords:###3d reconstruction, rgb-d scanning, 3d learning, 3d scene understanding', 'tL_DL': 'TL;DR:###From an incomplete RGB-D scan of a scene, we aim to detect the individual object instances comprising the scene and infer their complete object geometry.', 'paper_decision_time': '08 Nov 2019', 'decision': 'Reject', 'paper_decision_commentlength': 0, 'review_publish_time': '28 Oct 2019 (modified: 06 Nov 2019)', 'rate': 3, 'review_score_one': 'Review Assessment: Thoroughness In Paper Reading:###I read the paper thoroughly.', 'review_score_two': 'Review Assessment: Checking Correctness Of Experiments:###I assessed the sensibility of the experiments.', 'review_score_three': 'Review Assessment: Checking Correctness Of Derivations And Theory:###N/A', 'review_contentlength': 3077}, {'title': '3D-SIC: 3D Semantic Instance Completion for RGB-D Scans | OpenReview', 'publish_time': '26 Sep 2019 (modified: 28 Nov 2019)', 'keywords': 'Keywords:###3d reconstruction, rgb-d scanning, 3d learning, 3d scene understanding', 'tL_DL': 'TL;DR:###From an incomplete RGB-D scan of a scene, we aim to detect the individual object instances comprising the scene and infer their complete object geometry.', 'paper_decision_time': '08 Nov 2019', 'decision': 'Reject', 'paper_decision_commentlength': 0, 'review_publish_time': '22 Oct 2019 (modified: 06 Nov 2019)', 'rate': 6, 'review_score_one': 'Review Assessment: Thoroughness In Paper Reading:###I read the paper at least twice and used my best judgement in assessing the paper.', 'review_score_two': 'Review Assessment: Checking Correctness Of Experiments:###I carefully checked the experiments.', 'review_score_three': 'Review Assessment: Checking Correctness Of Derivations And Theory:###I carefully checked the derivations and theory.', 'review_contentlength': 1780}]}\n",
      "{'columns': ['rate', 'arxiv', 'keywords', 'title', 'cite', 'avgscore', 'fangcha'], 'head': [{'rate': 2.0, 'arxiv': -1, 'keywords': 'maximum mean discrepancy, kernelized Stein Discrepancy, RKHS, two-sample test, empirical estimator, discrete distributions', 'title': 'a generalized probability kernel on discrete distributions and its application in two-sample test', 'cite': 0, 'avgscore': 2.0, 'fangcha': 0.5}, {'rate': 2.0, 'arxiv': -1, 'keywords': 'adversarial robustness, resisting adversarial examples', 'title': 'towards counteracting adversarial perturbations to resist adversarial examples', 'cite': 0, 'avgscore': 2.0, 'fangcha': 0.5}, {'rate': 2.25, 'arxiv': 'failed', 'keywords': 'Distributed Machine Learning, Federated Learning, Distributed Averaging Consensus', 'title': 'consensus driven learning', 'cite': 0, 'avgscore': 2.25, 'fangcha': 0.6875}, {'rate': 2.25, 'arxiv': -1, 'keywords': 'Graph embedding, Theory, Topology, Functional analysis', 'title': '$graph embedding via topology and functional analysis$', 'cite': 0, 'avgscore': 2.25, 'fangcha': 0.1875}, {'rate': 2.25, 'arxiv': -1, 'keywords': 'text generation, knowledge graph', 'title': 'ketg: a knowledge enhanced text generation framework', 'cite': 0, 'avgscore': 2.25, 'fangcha': 0.1875}]}\n",
      "{'columns': ['rate', 'decision', 'keywords', 'title', 'citenum', 'cite', 'avgscore', 'fangcha'], 'head': [{'rate': nan, 'decision': 'Reject', 'keywords': 'continuous extensions, algorithmic reasoning, set functions, machine learning, combinatorial optimization, image classification', 'title': 'neural extensions: training neural networks with set functions', 'citenum': -1.0, 'cite': 0, 'avgscore': 0.0, 'fangcha': 0.0}, {'rate': nan, 'decision': 'Reject', 'keywords': 'Nearest neighbor search, tree algorithms, graph cuts, random projections', 'title': 'cluster tree for nearest neighbor search', 'citenum': nan, 'cite': 0, 'avgscore': 0.0, 'fangcha': 0.0}, {'rate': nan, 'decision': 'Reject', 'keywords': 'minimizing parameter l2 norm, representation cost, implicit bias', 'title': 'inductive bias of multi-channel linear convolutional networks with bounded weight norm', 'citenum': 9.0, 'cite': 9, 'avgscore': 0.0, 'fangcha': 0.0}, {'rate': nan, 'decision': 'Reject', 'keywords': 'extensive form games, network extensive form games, online learning, optimistic gradient descent ascent', 'title': 'fast convergence of optimistic gradient ascent in network zero-sum extensive form games', 'citenum': -1.0, 'cite': 0, 'avgscore': 0.0, 'fangcha': 0.0}, {'rate': nan, 'decision': 'Reject', 'keywords': 'neuron type classification, convolutional neural network, electrophysiology', 'title': 'neocortical cell type classification from electrophysiology recordings using deep neural networks', 'citenum': -1.0, 'cite': 0, 'avgscore': 0.0, 'fangcha': 0.0}]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "excel_file = pd.ExcelFile(file_path)\n",
    "\n",
    "# Display sheet names\n",
    "print(excel_file.sheet_names)\n",
    "\n",
    "# Load each sheet into a dictionary\n",
    "sheets = {sheet_name: excel_file.parse(sheet_name) for sheet_name in excel_file.sheet_names}\n",
    "\n",
    "# Prepare summaries for each sheet\n",
    "sheet_summaries = {}\n",
    "for name, df in sheets.items():\n",
    "    summary = {\n",
    "        \"columns\": df.columns.tolist(),\n",
    "        \"head\": df.head().to_dict(orient=\"records\")\n",
    "    }\n",
    "    sheet_summaries[name] = summary\n",
    "for sum in sheet_summaries:\n",
    "  print(sheet_summaries[sum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7bvBbX7KzPn"
   },
   "source": [
    "We have a dataset split in six sheets, each representing different years of the review process for some conference.\n",
    "\n",
    "| Sheet  | Rows  | Columns | Notes                                                                 |\n",
    "|--------|-------|---------|-----------------------------------------------------------------------|\n",
    "| Sheet1 | 1495  | 22      | Many unnamed columns (e.g., 'Unnamed: 1', 'F', 'G'), likely noisy; includes abstract, decision, review, rates |\n",
    "| Sheet2 | 2849  | 12      | Some columns in Chinese ('序号' = index, '方差' = variance); has derived stats like avgscore, confidence sum |\n",
    "| Sheet3 | 4733  | 12      | Includes submission dates, IDs, abstract/keywords, rates, and decisions |\n",
    "| Sheet4 | 7769  | 19      | Rich metadata (e.g., review times, reviewer level, comment length), cleaner naming |\n",
    "| Sheet5 | 3457  | 25      | Multiple reviewers' scores, citation info, and a mix of identifiers |\n",
    "| Sheet6 | 2966  | 26      | Very similar to Sheet5 but with some extra fields like 'arxiv', more structured reviewer columns |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SXroRBmdK2ym"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a prompt with sheet summaries\n",
    "prompt = \"I have an Excel file with multiple sheets, this dataset represent the openreview dataset with information about the review process of some papers, my objective is to extract information that could help write better papers. Each sheet has the following structure:\\n\\n\"\n",
    "\n",
    "for name, summary in sheet_summaries.items():\n",
    "    columns = ', '.join(summary['columns'])\n",
    "    first_row = summary['head'][0] if summary['head'] else {}\n",
    "    first_row_str = json.dumps(first_row)\n",
    "    prompt += f\"[Sheet: {name} | Columns: {columns} ] \"\n",
    "\n",
    "prompt += \"Can you compare these sheets, highlight the differences in their structures, explain the different labels, and suggest how I might align them for a unified analysis? I want you to provide a deep detailed explanations of the previous points\"\n",
    "\n",
    "# Get GPT-4's response\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"openai/gpt-4\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a data analyst.\"},\n",
    "#         {\"role\": \"user\", \"content\": prompt}\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Print GPT-4's response\n",
    "# print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVuJ2nLHK0ti"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# Output of previous request:\n",
    "\n",
    "Let's take a look at the structure of each of the Excel sheets:\n",
    "\n",
    "**Sheet1** has columns such as title1, abstract, keywords, title, decision, rate, confidence, review, etc. It mostly contains initial attributes of the papers, like the title, abstract, keywords, and review-related data like decision, rate, confidence to judge and review content.\n",
    "\n",
    "**Sheet2** has a mix of Chinese and English columns like 序号 (Number), title, confidence, rate源 (Rate Source), review, reviewLength, accept, confidence分数 (Confidence Score), confidence总和 (Total Confidence), avgscore, rate, 方差 (variance). It contains a detailed scoring and review related data, with added information about review lengths, acceptance status and aggregate information such as total confidence, average score, and variance.\n",
    "\n",
    "**Sheet3** has auto_increase, id, title, submit_date, decision, Confidence, rate1, rate, review, abstract_field, keyword_field, etc. It carries submission level data like title, submission date, deposition and reviews along with basic paper attributes like abstract and keywords.\n",
    "\n",
    "**Sheet4** has more details about paper review process and timelines, abstract, keyword, titlelength, paper_decision_time, decision, paper_decision_comment, paper_decision_commentlength, review, review_contentlength, etc. with some attributes from earlier sheets like title, decision etc.\n",
    "\n",
    "**Sheet5** and **Sheet6** seem to be identical in their structure, containing detailed paper review ratings, decision, reviewer details, chairs, title, keywords, abstract, etc., along with citation-related details citenum, cite, link1 and some aggregation values like avgscore, fangcha (variance in Chinese).\n",
    "\n",
    "Now, comparing these sheets:\n",
    "\n",
    "1. Some columns such as 'title', 'review', 'rate', 'confidence', 'decision', 'abstract', 'keywords' seem common between almost all sheets and can form a baseline to join or combine these sheets.\n",
    "2. Sheet1 has multiple unnamed columns that may make merging with other sheets challenging.\n",
    "3. Sheet2 has some columns in Chinese which need translation or mapping with other English columns if suitable.\n",
    "4. Sheet2, Sheet5, and Sheet6 have columns that provide aggregate information or metrics derived from raw data e.g., avgscore, variance (in Chinese) that might not be available in other sheets.\n",
    "5. Sheets 4, 5, and 6 provide more process control level data related to paper review process and timeline of events.\n",
    "6. Sheets 5 and 6 have more citation and referencing related details like 'citenum', 'cite', 'link' along with reviewer related data which the other sheets may lack.\n",
    "7. The 'id' and 'paper_id' could communicate between different sheets for combination, if they are the same.\n",
    "\n",
    "Based on this, here are some recommendations to align the sheets for a unified analysis:\n",
    "\n",
    "1. Investigate the unnamed columns: Before proceeding with any data alignment, it would be worthwhile to explore these unnamed columns for potential useful data.\n",
    "\n",
    "2. Translate the Chinese language columns: To make merging of the datasets easier, translate the Chinese columns into English if feasible or find their corresponding English fields in other sheets.\n",
    "\n",
    "3. Standardize column naming: You may need to consider renaming or aliasing columns that represent the same attributes in different sheets for easy merging. For instance, 'title1' in Sheet1 could be renamed to 'title' for consistency across sheets.\n",
    "\n",
    "4. Merge using common columns: Consider merging datasets based on common columns such as 'title', 'abstract', 'keywords', 'rate', 'review', 'confidence', 'decision' or ‘id’, ‘paper_id’, etc.\n",
    "\n",
    "5. Handling derived metrics: Columns that contain derived information like 'avgscore' , 'fangcha', 'rate0' through 'rate6', etc. in Sheet2, Sheet5, and Sheet6 need to be handled carefully as they might not align directly with raw data in other sheets. The logic or method of their calculation needs to be reviewed to see if similar can be derived from other sheets.\n",
    "\n",
    "6. Combining reviewing process-related data: Consider merging reviewer-related data like 'review_score_one', 'review_score_two', 'review_score_three' from Sheet4 with respective details from Sheet5 and Sheet6. Do a similar approach for paper decision and reviewing process-related data.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJSC-lrgowB4"
   },
   "source": [
    "### Columns Ranking\n",
    "\n",
    "We can explore the data and the columns to see the most meaninguful ones.\n",
    "\n",
    "**High Importance (Core columns, appear in ≥3 sheets)**:\n",
    "\n",
    "* title (6): Identifier for papers.\n",
    "* decision (5): Outcome of the review process: acceptance or rejection.\n",
    "* abstract (4): Insights on the content of the paper.\n",
    "* review (4): Full review text.\n",
    "* rate, rate1: Numerical review scores.\n",
    "* confidence, avgscore, keywords: Reviewer confidence, mean score.\n",
    "* keywords: another insight on the content of the paper.\n",
    "\n",
    "**Medium Importance (Moderate usage or derived metrics)**:\n",
    "* paper_id, rate0 to rate6: Breakdown of scores per reviewer.\n",
    "* reviewer0 to reviewer4: Individual reviewers.\n",
    "* cite, fangcha (variance), chairs, link1, Title1.\n",
    "\n",
    "**Low Importance / Noisy / One-off**, these appear only once or are ambiguous:\n",
    "* Columns like e, f, g, unnamed: 1, unnamed: 11, etc.\n",
    "* Chinese-only: 序号, 方差, rate源 — likely derivatives of others.\n",
    "* Specialized metadata: tl_dl, titlelength, review_publish_time, review_score_one, arxiv.\n",
    "These should be discarded or deprioritized in correlation analysis unless later needed for specific modeling.\n",
    "\n",
    "Overall, some columns names were missing or imprecise, requiring to manually explore the data to be able to rename them accordingly.\n",
    "\n",
    "### Notes\n",
    "\n",
    "From sheets 1 to 4 we have a **review-per-row**, meaning that each row represents a single evaluation from a reviewer; thus, a paper is represented by more rows. For sheets 5 and 6, instead, we have a **paper-per-row** meaning that the different comments from the reviewers are in different columns of the same rows.\n",
    "This discrepancy between sheets might mislead the analysis, however, we decided to keeps the representation as in the original data, due to time constraints.\n",
    "In general, **review-per-row** can be used for fine-grained analysis of individual reviewer feedback and it enables statistical summaries like average score, disagreement, or sentiment. On the other hand, **paper-per-row** is easier for summarizing overall reception and it is a cleaner format for descriptive analytics, e.g., decision outcome based on scores or comments.\n",
    "\n",
    "Sheets 5 and 6, includes for each paper the link to the webpage describing the corresponding review process, by following the link we discovered that also the submitted paper was available. We decided to retrieve some papers to perform a **manual information extraction** via LLMs described in the last section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr-rz8M7oFmY"
   },
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Objective of the Work\n",
    "The purpose of this cleaning procedure is to prepare a consistent and noise-free dataset for analyzing the characteristics that distinguish accepted from rejected papers on OpenReview. The ultimate goal is to identify useful patterns to improve the writing and structure of a scientific paper.\n",
    "\n",
    "## Cleaning Steps and Motivations\n",
    "\n",
    "### 1. Column Standardization\n",
    "- Column names referring to the same concept but labeled differently were unified (e.g., abstract_field → abstract, keyword_field → keywords, title1 → title).\n",
    "- Purpose: ensure consistency across sheets to facilitate data merging and cross-analysis.\n",
    "\n",
    "### 2. Review Unification\n",
    "- Columns such as reviewer0, reviewer1, etc., were concatenated into a single review column.\n",
    "- Purpose: provide a compact and comprehensive textual representation of the feedback received by each paper.\n",
    "\n",
    "### 3. Handling of rate Columns\n",
    "- In sheets with multiple rating columns (e.g., rate1, rate2), the average was calculated, ignoring zeros.\n",
    "- Purpose: obtain a meaningful and synthetic measure of the paper's evaluation.\n",
    "\n",
    "### 4. Standardization of the decision Column\n",
    "- Multiple decision variants (e.g., decision1, decision123) were merged into a single decision column.\n",
    "- Numerical values (\"0\", \"1\") were converted into textual labels: \"Reject\" and \"Accept\".\n",
    "- Purpose: obtain a consistent categorical column for outcome classification.\n",
    "\n",
    "### 5. Removal of Low-Coverage Columns\n",
    "- Columns filled in less than 1% of the rows were eliminated.\n",
    "- Purpose: remove noisy and uninformative dimensions for statistical modeling.\n",
    "\n",
    "### 6. Removal of Columns Containing Links\n",
    "- Columns containing URLs (e.g., http://...) were removed as they are not relevant for analysis.\n",
    "\n",
    "### 7. Final Cleanup of Redundant Columns\n",
    "- In Sheet2, the column accept was renamed to decision for semantic consistency.\n",
    "- In Sheet5, the chairs column was removed.\n",
    "- In all sheets, only the title column was kept; duplicates like title1 were dropped.\n",
    "\n",
    "### 8. Basic Text Cleaning\n",
    "- Basic text preprocessing was applied: converting to lowercase, removing special characters, extra spaces, and irrelevant text portions.\n",
    "- Purpose: ensure uniformity in textual fields for subsequent NLP or classification tasks.\n",
    "\n",
    "### 9. Removal of Non-Significant Columns\n",
    "- Throughout the process, columns deemed irrelevant to the goal of identifying patterns useful for improving paper acceptance probability were removed.\n",
    "\n",
    "## Conclusion\n",
    "This data cleaning process has transformed a heterogeneous dataset into a clean, consistent, and analytically usable version. It now enables reliable statistical or machine learning analysis to discover patterns among paper features and their acceptance likelihood. This forms a solid basis for providing actionable and data-driven advice to researchers preparing a scientific paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmsk07ddgmNw"
   },
   "source": [
    "# Knowledge Extraction from Paper Acceptance Data using BERT-based NLP Techniques\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "The primary objective is to extract actionable insights that can guide researchers in crafting more effective paper submissions by leveraging natural language processing (NLP) techniques and machine learning-based topic modeling.\n",
    "\n",
    "### 1.1 Dataset Overview\n",
    "\n",
    "The dataset includes the following key fields:\n",
    "- `title`: Title of the paper.\n",
    "- `keywords`: Keywords assigned by authors.\n",
    "- `decision`: Outcome of the submission (\"Accept\" or \"Reject\").\n",
    "- `rate` / `avgscore`: Numerical score given by reviewers.\n",
    "- `review_publish_time`, `paper_decision_time`: Timestamps for tracking timelines.\n",
    "- `review_contentlength`, `paper_decision_commentlength`: Length of review and final decision comments.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Methodology\n",
    "\n",
    "### 2.1 Data Preprocessing\n",
    "\n",
    "Data was extracted from Excel sheets containing multiple years of conference submissions. Each sheet was processed independently to ensure modularity and flexibility across different editions of the same conference.\n",
    "\n",
    "Key preprocessing steps included:\n",
    "- Cleaning and standardizing keyword formatting (`Keywords:###BERT, model compression` → `[\"BERT\", \"model compression\"]`)\n",
    "- Extracting clean decisions (`Accept` / `Reject`)\n",
    "- Computing title lengths and extracting n-grams (bigrams, trigrams)\n",
    "\n",
    "### 2.2 Natural Language Processing with BERT\n",
    "\n",
    "#### 2.2.1 Topic Modeling via BERTopic\n",
    "\n",
    "To identify thematic differences between accepted and rejected papers, we employed **BERTopic**, a state-of-the-art topic modeling technique based on BERT embeddings. This method allows for:\n",
    "- Unsupervised clustering of titles into semantically coherent topics\n",
    "- Comparison of dominant topics in accepted vs. rejected papers\n",
    "- Insight into which themes are most associated with successful submissions\n",
    "\n",
    "BERTopic leverages transformer-based contextual embeddings to capture nuanced semantic relationships between paper titles, offering a richer alternative to traditional methods like LDA.\n",
    "\n",
    "#### 2.2.2 Keyword Analysis\n",
    "\n",
    "We analyzed the frequency and distribution of keywords in accepted and rejected papers. In particular, we calculated:\n",
    "- Absolute frequency of each keyword\n",
    "- Relative lift: how much more likely a keyword appears in accepted papers compared to all papers\n",
    "\n",
    "This allowed us to identify keywords strongly correlated with acceptance.\n",
    "\n",
    "#### 2.2.3 Power Words in Titles\n",
    "\n",
    "Using bigram and trigram analysis, we identified frequent combinations of words appearing in paper titles. These were compared across accepted and rejected sets to uncover linguistic patterns that may influence reviewer perception.\n",
    "\n",
    "#### 2.2.4 Correlation Between Review Scores and Outcomes\n",
    "\n",
    "Where available, we analyzed numerical review scores (`rate` or `avgscore`) to determine:\n",
    "- Average scores for accepted vs. rejected papers\n",
    "- Distribution of scores within each group\n",
    "- Threshold values that correlate with acceptance\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Future Work\n",
    "\n",
    "- **Sentiment and linguistic pattern analysis using LLMs**:  \n",
    "  Feed the full review texts and final decision comments into a Large Language Model (e.g., GPT, Llama, Mistral) to extract qualitative differences between accepted and rejected papers. This could highlight:\n",
    "  - Common reasons for rejection (e.g., lack of novelty, insufficient experiments)\n",
    "  - Phrases or argument structures associated with acceptance\n",
    "  - Tone, clarity, and persuasiveness in reviewer feedback\n",
    "\n",
    "  This would complement the current quantitative approach with deeper qualitative insights that are difficult to extract via traditional NLP methods.\n",
    "\n",
    "- **Automated classification** of paper abstracts to predict acceptance likelihood\n",
    "- Integration of **citation graphs** to assess prior work coverage\n",
    "- Analysis of **reviewer engagement** through comment length and detail level\n",
    "- Correlation between **reviewer agreement** and final decision outcome\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJKBb66TBzll",
    "outputId": "7c86e1a4-f231-45b4-b372-d78adde1fccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Collecting BERTopic\n",
      "  Downloading bertopic-0.17.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting Counter\n",
      "  Downloading Counter-1.0.0.tar.gz (5.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from BERTopic) (0.8.40)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from BERTopic) (5.24.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from BERTopic) (1.6.1)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from BERTopic) (4.1.0)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from BERTopic) (4.67.1)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from BERTopic) (0.5.7)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->BERTopic) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->BERTopic) (1.5.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->BERTopic) (9.1.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->BERTopic) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->BERTopic) (3.6.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->BERTopic) (4.51.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->BERTopic) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->BERTopic) (0.31.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->BERTopic) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->BERTopic) (4.13.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->BERTopic) (0.60.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->BERTopic) (0.5.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->BERTopic) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->BERTopic) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->BERTopic) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->BERTopic) (2.32.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->BERTopic) (0.43.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->BERTopic) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->BERTopic) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->BERTopic) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->BERTopic) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->BERTopic) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->BERTopic) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->BERTopic) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->BERTopic) (2025.4.26)\n",
      "Downloading bertopic-0.17.0-py3-none-any.whl (150 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: Counter\n",
      "  Building wheel for Counter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Counter: filename=Counter-1.0.0-py3-none-any.whl size=5392 sha256=1b8eca98a5e1549c735471639a6390c6ca67b5df09485c985429f7e232aa8546\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/5b/a0/8f15503db6a45a1d8747bf0f1438411cb37484ac4dfdfe6c0b\n",
      "Successfully built Counter\n",
      "Installing collected packages: Counter, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, BERTopic\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed BERTopic-0.17.0 Counter-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas BERTopic Counter numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "048ce7868c974af5986d3155fc3dc3c1",
      "1f26a79b20274608bc11750883402074",
      "8e79c8b294054a6bb939a31c9c84cf78",
      "c07ffee55de14770a4e255a36ad6df7c",
      "dbfb7e5bcba14d189f475cd770da9e2c",
      "cfc1707ca7a04dab85de914aa5c0e820",
      "a45f98b9ab004be191aab095f38aa289",
      "c89208694aee494491928a5c9610b01a",
      "2d022d11d50147488283fd7220095a1a",
      "0b425aab3be847609a41d671bc88f88a",
      "848ed9836179439593070e7b7e2ee501",
      "e97d704291b243d584735afc4dc5398e",
      "4836b857974f42079a546ed8bcfa5db6",
      "d50cbb22bacc44d9bf9c19848cb788a7",
      "330f24c657404ab5a124feb95152b24f",
      "c46e405354fd4a609780ee396c1f8e5f",
      "487b2e6ab9cb48afb22fb603a2311971",
      "38dd3e912cd043f89858c28255a2a9ae",
      "2f5b2cfabfa14223b62dea97d7ab29cf",
      "f35b7bca7ea74703af41991ca9089e11",
      "8fda2b299edc40a6b28d250aba1033b2",
      "29d288429c8444a282f1ae509b394fbd",
      "e8009ac969134d3783c3c8f04fca2ba9",
      "b5f26b28b96345f5bf90f7833cacb4d0",
      "2fb51d2c413a462ab9dc951331456667",
      "493fef8158f84a55a4e7bf220508ca9d",
      "521a8bcdc4f24bbbb285cef883c0c05c",
      "fbac9cfb7c244fdfaebd7dfbce477ee2",
      "98d8dcb86e874441ac06bca3f47cdd9f",
      "e21dd1e9147e41448414301ee4f44a12",
      "6918c3b2ffe448f78c0c93365d5e793f",
      "b8ca1935a9224d899815abb610be4fa5",
      "69e48c4b130f4060851c77038ff2d4a7",
      "405c0299c23145dd8c6f7fe790ebdba2",
      "bab84a600c894c54a51bc370752a5c63",
      "6ea4269dc8e5440da5752eeecfd07afc",
      "2f5c2b5f8b214336a4d4f0a4d0cb1e29",
      "ce164f6b37934b6bacccc0bb0a9f2868",
      "6c52a219b9a043359f45d7203cbcd45d",
      "a1d88b678278467c892bf9870670091b",
      "e6d812bffb044b029758929fc2416016",
      "f56334915ae24d7b96d76e7637b0b3fc",
      "d087e6ee4976478ea19d9ae4cc46f402",
      "ab499233786241619560da928ba85517",
      "9c909c1bacad421486a9059e7e3daf00",
      "820f19d9c6e24bf78a6a4beb46b26968",
      "95561c0d72e0423b910bb0b4aeeae110",
      "ab9364587b1e4f8bbaefb909f5b8d013",
      "18c80a054cdd4c9db8c356b541945ec7",
      "6816300cbefa4bacaef4bd6c1816d983",
      "fe89757f6605465dbea0e90e140416fe",
      "a84e4d15535f46719241c7a0b45b3ac8",
      "2e5ce53788bc497bb12b888cbeeb1d08",
      "56ddbec5d4a54c31b39c184f29e8e84e",
      "fb337ec946cf4fb489608c4743e222dc",
      "4b744854f86c4cf78e18d7224d719412",
      "fbb028a97dd14f7290f72693e66b4dfa",
      "d82e074d3fcc4944af1619ba24525b9b",
      "e005fc7e5b424b90969e2e8890d443e9",
      "5c3d126ec27344a7b96f2df3e659f8d6",
      "a15f8c9982cc4fb591fa3ac64108c84b",
      "5132a3a10adb4e4faaadefb3a6a5f68d",
      "c1a189a73b3447d2be3fa757a5f9517f",
      "8dd5e29c16874004840d3c47c27fff0c",
      "62242c89ac7a41d9b72aa86f31c4ca42",
      "1a7838ef159641c8ad0903cbed39c1c5",
      "2606ac29ebf04fccad7663aaaac25fa8",
      "3cf505c9b0684fa882873c061367fdaf",
      "75e3074cc9e74243bbc7f9326676d970",
      "ed0bb11686664772b700136027f512db",
      "d51dcfa5a3f2455aa6a20c9fbfb97f17",
      "7da15a52d7464079be71a2cc4dab0f22",
      "9473f8faf298467391f24a24d39601e5",
      "4fe644c130b94f4fb63fa274c8fc8e81",
      "28a7cc5b93a441138645671a2b10f7a6",
      "a0c2de45dbcc4aae80e94caaecedc094",
      "f2e99bc18ff444b4b7e8a183d720be15",
      "5f6573f557e64f87837b578391ee9005",
      "acb8bb2bc2e249588afd98d5258d742c",
      "a60c75655a9f44f29fa48d33e7898097",
      "7c6649231e0242adb3ef421ac592d833",
      "a4d033b32a324f63b6cd58e28a96dcca",
      "beac4858fdff4c2e9cb81728465a80fc",
      "744993ca399a4e5581e649bb34b64db3",
      "c52a8b0beb8b4a37b5bbba4e5438c93f",
      "a8beff6271de40058675e3794662c83c",
      "6f80cf1648654813a9f5b2c1c23e8f6d",
      "ede1351bae8147da9a299a7cb1a36518",
      "bc96b2e2dc6f4afba610555e62067159",
      "bf8c4ac65e5c490089423fa4f36af466",
      "77b09b2b6f32419ab56c9e9b4fb3b6f7",
      "c8dfec8c73c146a09200c960f306f87e",
      "bd2f5f05bf7a4e9ca33654af0a46c76a",
      "be2e1b57b4eb483aa2a60daa20aff685",
      "c135f68322554d259bdfdabf91f88950",
      "af5e52197f4147eba3cec62892e89d5f",
      "b70f89abe3f94a7f846e9bde461be332",
      "31044eeadda34be5acd2fa2848ead9b3",
      "e6ee55e082fd4c2a8f868f88e3735c1f",
      "4aeaea4ef6e54474ba88238a1769200c",
      "110a93b77baf40cdacf05a75d2ac0979",
      "69818a32d73a470ab2b4b687c11cc73d",
      "97f306ea17494df3a61ad053027d7931",
      "7d1425ac93914b228c21a3dfeaf9089f",
      "72776bf3ffc24d4a911e6266da32f3b1",
      "6122ccf9ff7e45748e6011507607a27b",
      "c1f90fec3e43413691aab054b51ad214",
      "761c294f135d48208a7d680df4b24181",
      "291996da91cd472d915187d7075991f5",
      "36e6083aaf10426982347290e2870536",
      "2bdaf76938844236a01343a4bf8a555d",
      "6064142c22fa4bd1b2fb875e2d9c6112",
      "2f68b2b41041484cac066d59d45df483",
      "67afe1442fa74cd4b83c52c3b6bce88b",
      "aab3997f84de44bb8117065d25b307a7",
      "11fb86e6291f4bb08d7b2e028b179704",
      "3c29b4c3509b4f9695235b81d1590b94",
      "f78bca298ed54f20b7f5c06c9310b2b1",
      "51cd5c18b6bd43f99526af5a91543824",
      "00b0bf554ca743ffbe4219bfd7e45dba",
      "f6203d914ead4b3aac7acd508a4e4171"
     ]
    },
    "id": "XjXANpXCAjzb",
    "outputId": "b19dcede-ccba-45c7-8b40-3bc861aa583a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File loaded successfully. Available sheets: ['Sheet1', 'Sheet2', 'Sheet3', 'Sheet4', 'Sheet6', 'Sheet5']\n",
      "\n",
      "========================================\n",
      "Starting analysis: Sheet1\n",
      "========================================\n",
      "Preparing sheet data...\n",
      "Data prepared: 1495 valid rows.\n",
      "\n",
      "COMPARATIVE ANALYSIS - SHEET 'Sheet1'\n",
      "Total papers: 1495\n",
      "Accepted: 607 (40.6%)\n",
      "Rejected: 742 (49.6%)\n",
      "\n",
      "Top 10 Most Common Keywords:\n",
      "keywords\n",
      "Deep learning                  1197\n",
      "Unsupervised Learning           323\n",
      "Computer vision                 317\n",
      "Natural language processing     315\n",
      "Applications                    251\n",
      "Supervised Learning             233\n",
      "Optimization                    192\n",
      "Reinforcement Learning          175\n",
      "Theory                          131\n",
      "Transfer Learning                95\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top Keywords in Accepted Papers:\n",
      "keywords\n",
      "Deep learning                  524\n",
      "Natural language processing    137\n",
      "Unsupervised Learning          123\n",
      "Computer vision                 99\n",
      "Reinforcement Learning          95\n",
      "Optimization                    93\n",
      "Applications                    90\n",
      "Supervised Learning             61\n",
      "Theory                          56\n",
      "Transfer Learning               41\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top Keywords in Rejected Papers:\n",
      "keywords\n",
      "Deep learning                  597\n",
      "Computer vision                188\n",
      "Unsupervised Learning          173\n",
      "Natural language processing    163\n",
      "Applications                   134\n",
      "Supervised Learning            122\n",
      "Optimization                    81\n",
      "Reinforcement Learning          66\n",
      "Theory                          57\n",
      "Transfer Learning               48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average number of words in titles: Total=9.3\n",
      "    Accepted=8.8, Rejected=9.7\n",
      "\n",
      "Average rating: Total=5.7\n",
      "    Accepted=6.9, Rejected=4.8\n",
      "\n",
      "Topic Modeling on Titles - SHEET 'Sheet1'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048ce7868c974af5986d3155fc3dc3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97d704291b243d584735afc4dc5398e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8009ac969134d3783c3c8f04fca2ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405c0299c23145dd8c6f7fe790ebdba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c909c1bacad421486a9059e7e3daf00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b744854f86c4cf78e18d7224d719412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2606ac29ebf04fccad7663aaaac25fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6573f557e64f87837b578391ee9005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc96b2e2dc6f4afba610555e62067159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aeaea4ef6e54474ba88238a1769200c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdaf76938844236a01343a4bf8a555d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Topics - Accepted:\n",
      "   Topic  Count                                            Name  \\\n",
      "0     -1      7       -1_residuals_fractalnet_ultradeep_without   \n",
      "1      0     40  0_optimization_to_imaginationbased_metacontrol   \n",
      "2      1     25            1_pruning_cnns_pooling_convolutional   \n",
      "3      2     20          2_quantization_ternary_trained_network   \n",
      "4      3     18                3_language_natural_level_compose   \n",
      "5      4     18           4_quasirecurrent_chaos_automatic_long   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [residuals, fractalnet, ultradeep, without, de...   \n",
      "1  [optimization, to, imaginationbased, metacontr...   \n",
      "2  [pruning, cnns, pooling, convolutional, convne...   \n",
      "3  [quantization, ternary, trained, network, towa...   \n",
      "4  [language, natural, level, compose, character,...   \n",
      "5  [quasirecurrent, chaos, automatic, long, extra...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [FractalNet: Ultra-Deep Neural Networks withou...  \n",
      "1  [Hyperband: Bandit-Based Configuration Evaluat...  \n",
      "2  [Faster CNNs with Direct Sparse Convolutions a...  \n",
      "3  [Trained Ternary Quantization | OpenReview, Tr...  \n",
      "4  [Program Synthesis for Character Level Languag...  \n",
      "5  [Automatic Rule Extraction from Long Short Ter...  \n",
      "\n",
      "Top Topics - Rejected:\n",
      "   Topic  Count                                             Name  \\\n",
      "0     -1     21              -1_graph_changing_dictionary_graphs   \n",
      "1      0     22               0_loss_residual_empirical_surfaces   \n",
      "2      1     21                  1_pruning_coarse_chess_concepts   \n",
      "3      2     19            2_recurrent_layer_connected_combining   \n",
      "4      3     18     3_features_fewshot_controllers_communicating   \n",
      "5      4     18  4_recurrent_continuous_comparators_dependencies   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [graph, changing, dictionary, graphs, adaption...   \n",
      "1  [loss, residual, empirical, surfaces, analysis...   \n",
      "2  [pruning, coarse, chess, concepts, divide, den...   \n",
      "3  [recurrent, layer, connected, combining, analy...   \n",
      "4  [features, fewshot, controllers, communicating...   \n",
      "5  [recurrent, continuous, comparators, dependenc...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [NEUROGENESIS-INSPIRED DICTIONARY LEARNING: ON...  \n",
      "1  [An Empirical Analysis of Deep Network Loss Su...  \n",
      "2  [The Incredible Shrinking Neural Network: New ...  \n",
      "3  [A Way out of the Odyssey: Analyzing and Combi...  \n",
      "4  [Communicating Hierarchical Neural Controllers...  \n",
      "5  [Dynamic Neural Turing Machine with Continuous...  \n",
      "========================================\n",
      "Finished analysis: Sheet1\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Starting analysis: Sheet2\n",
      "========================================\n",
      "Preparing sheet data...\n",
      "Data prepared: 2849 valid rows.\n",
      "\n",
      "COMPARATIVE ANALYSIS - SHEET 'Sheet2'\n",
      "Total papers: 2849\n",
      "Accepted: 1051 (36.9%)\n",
      "Rejected: 1519 (53.3%)\n",
      "\n",
      "No keywords available for analysis.\n",
      "\n",
      "Average number of words in titles: Total=9.7\n",
      "    Accepted=9.4, Rejected=9.8\n",
      "\n",
      "Average rating: Total=5.4\n",
      "    Accepted=6.4, Rejected=4.6\n",
      "\n",
      "Topic Modeling on Titles - SHEET 'Sheet2'\n",
      "\n",
      "Top Topics - Accepted:\n",
      "   Topic  Count                                               Name  \\\n",
      "0     -1     16     -1_examplebased_existing_insufficiency_pixelnn   \n",
      "1      0     33                         0_word_lstms_sentence_text   \n",
      "2      1     21     1_classification_analyze_betweenclass_rewiring   \n",
      "3      2     21  2_quantization_structured_variational_alternating   \n",
      "4      3     19                    3_recurrent_skip_state_sequence   \n",
      "5      4     18         4_metalearning_bayes_competitive_attentive   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [examplebased, existing, insufficiency, pixeln...   \n",
      "1  [word, lstms, sentence, text, representations,...   \n",
      "2  [classification, analyze, betweenclass, rewiri...   \n",
      "3  [quantization, structured, variational, altern...   \n",
      "4  [recurrent, skip, state, sequence, diffusion, ...   \n",
      "5  [metalearning, bayes, competitive, attentive, ...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [On the insufficiency of existing momentum sch...  \n",
      "1  [Beyond Word Importance: Contextual Decomposit...  \n",
      "2  [An image representation based convolutional n...  \n",
      "3  [Variational Network Quantization | OpenReview...  \n",
      "4  [Initialization matters: Orthogonal Predictive...  \n",
      "5  [Meta-Learning and Universality: Deep Represen...  \n",
      "\n",
      "Top Topics - Rejected:\n",
      "   Topic  Count                                               Name  \\\n",
      "0     -1     18  -1_recommendations_optimizer_sessionbased_twol...   \n",
      "1      0     34     0_generative_improve_adversarial_collaborative   \n",
      "2      1     30                    1_state_reward_robot_modelbased   \n",
      "3      2     28         2_perturbations_saliency_ensembles_methods   \n",
      "4      3     25                3_embeddings_word_connected_compute   \n",
      "5      4     25               4_optimizing_generative_space_latent   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [recommendations, optimizer, sessionbased, two...   \n",
      "1  [generative, improve, adversarial, collaborati...   \n",
      "2  [state, reward, robot, modelbased, reinforceme...   \n",
      "3  [perturbations, saliency, ensembles, methods, ...   \n",
      "4  [embeddings, word, connected, compute, alone, ...   \n",
      "5  [optimizing, generative, space, latent, ration...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [Theoretical properties of the global optimize...  \n",
      "1  [Image Quality Assessment Techniques Improve T...  \n",
      "2  [TOWARDS ROBOT VISION MODULE DEVELOPMENT WITH ...  \n",
      "3  [DETECTING ADVERSARIAL PERTURBATIONS WITH SALI...  \n",
      "4  [On the Use of Word Embeddings Alone to Repres...  \n",
      "5  [Optimal transport maps for distribution prese...  \n",
      "========================================\n",
      "Finished analysis: Sheet2\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Starting analysis: Sheet3\n",
      "========================================\n",
      "Preparing sheet data...\n",
      "Data prepared: 4733 valid rows.\n",
      "\n",
      "COMPARATIVE ANALYSIS - SHEET 'Sheet3'\n",
      "Total papers: 4733\n",
      "Accepted: 1526 (32.2%)\n",
      "Rejected: 3207 (67.8%)\n",
      "\n",
      "Top 10 Most Common Keywords:\n",
      "keywords\n",
      "deep learning              449\n",
      "nan                        387\n",
      "reinforcement learning     265\n",
      "Deep Learning              181\n",
      "Reinforcement Learning     162\n",
      "optimization               118\n",
      "unsupervised learning      115\n",
      "generative models          111\n",
      "representation learning    106\n",
      "meta-learning               94\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top Keywords in Accepted Papers:\n",
      "keywords\n",
      "deep learning              145\n",
      "reinforcement learning     105\n",
      "nan                         66\n",
      "unsupervised learning       52\n",
      "Deep Learning               51\n",
      "optimization                51\n",
      "generative models           49\n",
      "Reinforcement Learning      46\n",
      "meta-learning               43\n",
      "representation learning     42\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top Keywords in Rejected Papers:\n",
      "keywords\n",
      "nan                        321\n",
      "deep learning              304\n",
      "reinforcement learning     160\n",
      "Deep Learning              130\n",
      "Reinforcement Learning     116\n",
      "optimization                67\n",
      "representation learning     64\n",
      "generalization              64\n",
      "unsupervised learning       63\n",
      "generative models           62\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average number of words in titles: Total=9.8\n",
      "    Accepted=9.6, Rejected=9.9\n",
      "\n",
      "Average rating: Total=5.3\n",
      "    Accepted=6.6, Rejected=4.7\n",
      "\n",
      "Topic Modeling on Titles - SHEET 'Sheet3'\n",
      "\n",
      "Top Topics - Accepted:\n",
      "   Topic  Count                                            Name  \\\n",
      "0     -1     11                         -1_odds_may_accuracy_be   \n",
      "1      0     27     0_generative_adversarial_computation_clouds   \n",
      "2      1     27           1_learn_bounces_distinct_dependencies   \n",
      "3      2     24  2_quantized_quantization_defensive_discretized   \n",
      "4      3     23     3_metalearning_unsupervised_parts_discovery   \n",
      "5      4     21                  4_graph_capsule_community_line   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [odds, may, accuracy, be, role, overparametriz...   \n",
      "1  [generative, adversarial, computation, clouds,...   \n",
      "2  [learn, bounces, distinct, dependencies, locat...   \n",
      "3  [quantized, quantization, defensive, discretiz...   \n",
      "4  [metalearning, unsupervised, parts, discovery,...   \n",
      "5  [graph, capsule, community, line, powerful, pr...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [Robustness May Be at Odds with Accuracy | Ope...  \n",
      "1  [Learning Localized Generative Models for 3D P...  \n",
      "2  [Generating Multiple Objects at Spatially Dist...  \n",
      "3  [ProxQuant: Quantized Neural Networks via Prox...  \n",
      "4  [Unsupervised Discovery of Parts, Structure, a...  \n",
      "5  [Predict then Propagate: Graph Neural Networks...  \n",
      "\n",
      "Top Topics - Rejected:\n",
      "   Topic  Count                                           Name  \\\n",
      "0     -1    103          -1_research_crossentropy_poor_problem   \n",
      "1      0     42                            0_na_muss_immer_man   \n",
      "2      1     39      1_language_document_pretraining_auxiliary   \n",
      "3      2     35  2_convolutional_advertisement_backdrop_column   \n",
      "4      3     30        3_codebook_binding_decisions_dictionary   \n",
      "5      4     27      4_generative_models_counterfactuals_boxes   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [research, crossentropy, poor, problem, margin...   \n",
      "1  [na, muss, immer, man, cakewalk, withdrawn, in...   \n",
      "2  [language, document, pretraining, auxiliary, m...   \n",
      "3  [convolutional, advertisement, backdrop, colum...   \n",
      "4  [codebook, binding, decisions, dictionary, exp...   \n",
      "5  [generative, models, counterfactuals, boxes, b...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [Using Deep Siamese Neural Networks to Speed u...  \n",
      "1  [NA | OpenReview, NA | OpenReview, NA | OpenRe...  \n",
      "2  [Language Modeling Teaches You More Syntax tha...  \n",
      "3  [IEA: Inner Ensemble Average within a convolut...  \n",
      "4  [Pearl: Prototype lEArning via Rule Lists | Op...  \n",
      "5  [Tinkering with black boxes: counterfactuals u...  \n",
      "========================================\n",
      "Finished analysis: Sheet3\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Starting analysis: Sheet4\n",
      "========================================\n",
      "Preparing sheet data...\n",
      "Data prepared: 7769 valid rows.\n",
      "\n",
      "COMPARATIVE ANALYSIS - SHEET 'Sheet4'\n",
      "Total papers: 7769\n",
      "Accepted: 2056 (26.5%)\n",
      "Rejected: 5713 (73.5%)\n",
      "\n",
      "Top 10 Most Common Keywords:\n",
      "keywords\n",
      "nan                            867\n",
      "deep learning                  494\n",
      "reinforcement learning         412\n",
      "Deep Learning                  318\n",
      "Reinforcement Learning         260\n",
      "representation learning        209\n",
      "meta-learning                  122\n",
      "GAN                            107\n",
      "optimization                   106\n",
      "natural language processing    105\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top Keywords in Accepted Papers:\n",
      "keywords\n",
      "nan                        200\n",
      "deep learning              170\n",
      "reinforcement learning     136\n",
      "Deep Learning               78\n",
      "Reinforcement Learning      69\n",
      "generalization              45\n",
      "optimization                44\n",
      "graph neural networks       43\n",
      "representation learning     41\n",
      "meta-learning               40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top Keywords in Rejected Papers:\n",
      "keywords\n",
      "nan                            667\n",
      "deep learning                  324\n",
      "reinforcement learning         276\n",
      "Deep Learning                  240\n",
      "Reinforcement Learning         191\n",
      "representation learning        168\n",
      "GAN                             88\n",
      "meta-learning                   82\n",
      "natural language processing     77\n",
      "generative models               74\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average number of words in titles: Total=9.9\n",
      "    Accepted=9.9, Rejected=9.9\n",
      "\n",
      "Average rating: Total=4.2\n",
      "    Accepted=6.2, Rejected=3.4\n",
      "\n",
      "Topic Modeling on Titles - SHEET 'Sheet4'\n",
      "\n",
      "Top Topics - Accepted:\n",
      "   Topic  Count                                              Name  \\\n",
      "0     -1     49              -1_use_advil_criticality_minibatches   \n",
      "1      0     25        0_capabilities_respect_triangle_inequality   \n",
      "2      1     25  1_inductive_structured_representation_graphsaint   \n",
      "3      2     24         2_adversarial_against_examples_robustness   \n",
      "4      3     22               3_knowledge_answering_question_over   \n",
      "5      4     21        4_languages_lottery_compositional_lifelong   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [use, advil, criticality, minibatches, stiefel...   \n",
      "1  [capabilities, respect, triangle, inequality, ...   \n",
      "2  [inductive, structured, representation, graphs...   \n",
      "3  [adversarial, against, examples, robustness, a...   \n",
      "4  [knowledge, answering, question, over, reasoni...   \n",
      "5  [languages, lottery, compositional, lifelong, ...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [To Relieve Your Headache of Training an MRF, ...  \n",
      "1  [An Inductive Bias for Distances: Neural Nets ...  \n",
      "2  [Inductive and Unsupervised Representation Lea...  \n",
      "3  [Fooling Detection Alone is Not Enough: Advers...  \n",
      "4  [Learning to Retrieve Reasoning Paths over Wik...  \n",
      "5  [Playing the lottery with rewards and multiple...  \n",
      "\n",
      "Top Topics - Rejected:\n",
      "   Topic  Count                                           Name  \\\n",
      "0     -1    224               -1_spike_states_dsvic_kolmogorov   \n",
      "1      0     35   0_datasets_compatibility_adverserial_corpora   \n",
      "2      1     34           1_recurrent_entanglement_fan_focused   \n",
      "3      2     31                    2_rl_adaptability_acutum_if   \n",
      "4      3     31           3_ticket_directional_mixup_practical   \n",
      "5      4     29  4_automodulators_both_bivariate_doautoencoder   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [spike, states, dsvic, kolmogorov, adaptation,...   \n",
      "1  [datasets, compatibility, adverserial, corpora...   \n",
      "2  [recurrent, entanglement, fan, focused, comput...   \n",
      "3  [rl, adaptability, acutum, if, entropic, lagra...   \n",
      "4  [ticket, directional, mixup, practical, innova...   \n",
      "5  [automodulators, both, bivariate, doautoencode...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [White Box Network: Obtaining a right composit...  \n",
      "1  [Generative Adversarial Networks For Data Scar...  \n",
      "2  [Decoupling Hierarchical Recurrent Neural Netw...  \n",
      "3  [SMiRL: Surprise Minimizing RL in Entropic Env...  \n",
      "4  [Boosting Ticket: Towards Practical Pruning fo...  \n",
      "5  [Implicit ?-Jeffreys Autoencoders: Taking the ...  \n",
      "========================================\n",
      "Finished analysis: Sheet4\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Starting analysis: Sheet6\n",
      "========================================\n",
      "Preparing sheet data...\n",
      "Warning: Column 'decision' not found. Accept/Reject analysis skipped.\n",
      "Data prepared: 2966 valid rows.\n",
      "\n",
      "COMPARATIVE ANALYSIS - SHEET 'Sheet6'\n",
      "No valid decisions ('Accept'/'Reject') found. Skipping Accept/Reject analysis.\n",
      "\n",
      "Top 10 Most Common Keywords:\n",
      "keywords\n",
      "nan                         384\n",
      "deep learning               137\n",
      "reinforcement learning      114\n",
      "Reinforcement Learning       85\n",
      "Deep Learning                83\n",
      "representation learning      80\n",
      "robustness                   49\n",
      "Representation Learning      44\n",
      "self-supervised learning     42\n",
      "generalization               41\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average number of words in titles: Total=7.9\n",
      "\n",
      "Average rating: Total=5.4\n",
      "\n",
      "Topic Modeling on Titles - SHEET 'Sheet6'\n",
      "========================================\n",
      "Finished analysis: Sheet6\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Starting analysis: Sheet5\n",
      "========================================\n",
      "Preparing sheet data...\n",
      "Data prepared: 3457 valid rows.\n",
      "\n",
      "COMPARATIVE ANALYSIS - SHEET 'Sheet5'\n",
      "Total papers: 3457\n",
      "Accepted: 1095 (31.7%)\n",
      "Rejected: 2362 (68.3%)\n",
      "\n",
      "Top 10 Most Common Keywords:\n",
      "keywords\n",
      "nan                         459\n",
      "reinforcement learning      118\n",
      "deep learning               111\n",
      "Reinforcement Learning       87\n",
      "representation learning      69\n",
      "Deep Learning                66\n",
      "self-supervised learning     50\n",
      "Graph Neural Networks        46\n",
      "generalization               46\n",
      "Federated Learning           46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top Keywords in Accepted Papers:\n",
      "keywords\n",
      "nan                        119\n",
      "reinforcement learning      40\n",
      "Reinforcement Learning      30\n",
      "deep learning               26\n",
      "representation learning     23\n",
      "Deep Learning               19\n",
      "Graph Neural Networks       17\n",
      "Transformer                 16\n",
      "robustness                  14\n",
      "generalization              14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top Keywords in Rejected Papers:\n",
      "keywords\n",
      "nan                         340\n",
      "deep learning                85\n",
      "reinforcement learning       78\n",
      "Reinforcement Learning       57\n",
      "Deep Learning                47\n",
      "representation learning      46\n",
      "self-supervised learning     36\n",
      "Federated Learning           34\n",
      "generalization               32\n",
      "robustness                   31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average number of words in titles: Total=8.3\n",
      "    Accepted=8.3, Rejected=8.4\n",
      "\n",
      "Average rating: Total=5.2\n",
      "    Accepted=6.6, Rejected=4.5\n",
      "\n",
      "Topic Modeling on Titles - SHEET 'Sheet5'\n",
      "\n",
      "Top Topics - Accepted:\n",
      "   Topic  Count                                     Name  \\\n",
      "0     -1    255                     -1_of_neural_and_the   \n",
      "1      0    144  0_reinforcement_policy_offline_learning   \n",
      "2      1     62  1_adversarial_robustness_robust_attacks   \n",
      "3      2     60           2_graph_networks_neural_graphs   \n",
      "4      3     39  3_transformers_vision_transformer_token   \n",
      "5      4     30          4_gans_generative_synthesis_gan   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [of, neural, and, the, for, networks, training...   \n",
      "1  [reinforcement, policy, offline, learning, gam...   \n",
      "2  [adversarial, robustness, robust, attacks, aga...   \n",
      "3  [graph, networks, neural, graphs, equivariant,...   \n",
      "4  [transformers, vision, transformer, token, vis...   \n",
      "5  [gans, generative, synthesis, gan, maps, image...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [temporal efficient training of spiking neural...  \n",
      "1  [imitation learning by reinforcement learning,...  \n",
      "2  [towards understanding the robustness against ...  \n",
      "3  [space-time graph neural networks, topological...  \n",
      "4  [how do vision transformers work?, quadtree at...  \n",
      "5  [do not escape from the manifold: discovering ...  \n",
      "\n",
      "Top Topics - Rejected:\n",
      "   Topic  Count                                               Name  \\\n",
      "0     -1    672                            -1_learning_data_for_of   \n",
      "1      0    114              0_graph_networks_graphs_convolutional   \n",
      "2      1     58  1_reinforcement_exploration_distributional_mod...   \n",
      "3      2     43              2_transformers_vision_transformer_are   \n",
      "4      3     42                 3_language_bert_translation_models   \n",
      "5      4     36         4_attention_mechanism_visual_selfattention   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [learning, data, for, of, in, and, the, with, ...   \n",
      "1  [graph, networks, graphs, convolutional, neura...   \n",
      "2  [reinforcement, exploration, distributional, m...   \n",
      "3  [transformers, vision, transformer, are, sharp...   \n",
      "4  [language, bert, translation, models, nlp, mac...   \n",
      "5  [attention, mechanism, visual, selfattention, ...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [domain-wise adversarial training for out-of-d...  \n",
      "1  [on locality in graph learning via graph neura...  \n",
      "2  [exploring the robustness of distributional re...  \n",
      "3  [polyvit: co-training vision transformers on i...  \n",
      "4  [dict-bert: enhancing language model pre-train...  \n",
      "5  [deep dynamic attention model with gate mechan...  \n",
      "========================================\n",
      "Finished analysis: Sheet5\n",
      "========================================\n",
      "\n",
      "Global Aggregated Analysis Across All Sheets\n",
      "\n",
      "Global Statistics:\n",
      "Total papers: 23269\n",
      "Average number of words in titles: 9.3\n",
      "Average number of words in accepted titles: 9.4\n",
      "Average number of words in rejected titles: 9.6\n",
      "Global average rating: 5.0\n",
      "Average rating for accepted papers: 6.5\n",
      "Average rating for rejected papers: 4.1\n",
      "\n",
      "Top 10 Global Keywords:\n",
      "[('nan', 2097), ('Deep learning', 1359), ('deep learning', 1191), ('reinforcement learning', 909), ('Reinforcement Learning', 769), ('Deep Learning', 648), ('representation learning', 464), ('Unsupervised Learning', 410), ('Computer vision', 345), ('Natural language processing', 321)]\n",
      "\n",
      "Top 10 Keywords in Accepted Papers:\n",
      "[('Deep learning', 548), ('nan', 385), ('deep learning', 341), ('reinforcement learning', 281), ('Reinforcement Learning', 240), ('Deep Learning', 148), ('Natural language processing', 138), ('Unsupervised Learning', 135), ('Optimization', 121), ('representation learning', 106)]\n",
      "\n",
      "Top 10 Keywords in Rejected Papers:\n",
      "[('nan', 1328), ('Deep learning', 713), ('deep learning', 713), ('reinforcement learning', 514), ('Reinforcement Learning', 430), ('Deep Learning', 417), ('representation learning', 278), ('Unsupervised Learning', 234), ('Computer vision', 211), ('Natural language processing', 167)]\n",
      "\n",
      "Most Common Bigrams in Titles:\n",
      "[(('|', 'openreview'), 16846), (('neural', 'networks'), 2059), (('networks', '|'), 1896), (('learning', '|'), 1482), (('reinforcement', 'learning'), 1234), (('learning', 'with'), 604), (('deep', 'neural'), 571), (('neural', 'network'), 570), (('learning', 'to'), 539), (('deep', 'learning'), 443)]\n",
      "\n",
      "Most Common Trigrams in Titles:\n",
      "[(('networks', '|', 'openreview'), 1896), (('learning', '|', 'openreview'), 1482), (('neural', 'networks', '|'), 994), (('reinforcement', 'learning', '|'), 523), (('deep', 'neural', 'networks'), 449), (('models', '|', 'openreview'), 408), (('deep', 'reinforcement', 'learning'), 274), (('generative', 'adversarial', 'networks'), 231), (('convolutional', 'neural', 'networks'), 218), (('graph', 'neural', 'networks'), 217)]\n",
      "\n",
      "Global Topic Modeling on All Titles:\n",
      "   Topic  Count                                       Name  \\\n",
      "0     -1   3460      -1_advantage_normalized_relu_sampling   \n",
      "1      0     96  0_federated_personalized_clients_agnostic   \n",
      "2      1     89  1_continual_hcnet_dualnetwork_orderrobust   \n",
      "3      2     80     2_adaptation_domain_wildly_multitarget   \n",
      "4      3     78    3_architecture_search_channellevel_cnas   \n",
      "5      4     76           4_active_coreset_mixmatch_oracle   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [advantage, normalized, relu, sampling, anomal...   \n",
      "1  [federated, personalized, clients, agnostic, p...   \n",
      "2  [continual, hcnet, dualnetwork, orderrobust, o...   \n",
      "3  [adaptation, domain, wildly, multitarget, self...   \n",
      "4  [architecture, search, channellevel, cnas, rep...   \n",
      "5  [active, coreset, mixmatch, oracle, introducin...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [Latent forward model for Real-time Strategy g...  \n",
      "1  [adaptive personalized federated learning, ada...  \n",
      "2  [Continual Learning via Neural Pruning | OpenR...  \n",
      "3  [Distribution Matching Prototypical Network fo...  \n",
      "4  [BETANAS: Balanced Training and selective drop...  \n",
      "5  [Training Data Distribution Search with Ensemb...  \n",
      "\n",
      "Global Topic Modeling + Topic-Decision Association:\n",
      "decision  accept  reject\n",
      "topic                   \n",
      "1368         1.0     0.0\n",
      "1354         1.0     0.0\n",
      "765          1.0     0.0\n",
      "1323         1.0     0.0\n",
      "1321         1.0     0.0\n",
      "...          ...     ...\n",
      "886          0.0     1.0\n",
      "883          0.0     1.0\n",
      "882          0.0     1.0\n",
      "521          0.0     1.0\n",
      "1124         0.0     1.0\n",
      "\n",
      "[1409 rows x 2 columns]\n",
      "\n",
      "Top Topics with Acceptance Keywords:\n",
      "Topic 1368: paying, twostream, bout, swim, zebrafish\n",
      "Topic 1354: monotonic, chunkwise, multihead, attention, openreview\n",
      "Topic 765: mutual, maximization, estimation, information, perspective\n",
      "Topic 1323: neurquri, inspector, answerability, requirement, reading\n",
      "Topic 1321: perexample, routing, solve, diversity, depth\n",
      "\n",
      "Keywords associated with high acceptance topics:\n",
      "Topic 1368 → paying, twostream, bout, swim, zebrafish\n",
      "Topic 1354 → monotonic, chunkwise, multihead, attention, openreview\n",
      "Topic 765 → mutual, maximization, estimation, information, perspective\n",
      "Topic 1323 → neurquri, inspector, answerability, requirement, reading\n",
      "Topic 1321 → perexample, routing, solve, diversity, depth\n",
      "Topic 1320 → holstep, logic, proving, theorem, higherorder\n",
      "Topic 1296 → normal, anomaly, projection, subspace, autoencoding\n",
      "Topic 1307 → repair, localize, program, jointly, dynamic\n",
      "Topic 1281 → pan, dilations, 2sphere, altaz, tshaped\n",
      "Topic 660 → multilingual, nonautoregressive, decoupled, translators, translation\n",
      "Topic 1294 → texttospeech, clarinet, wave, voice, scaling\n",
      "Topic 1293 → transforms, scattering, pruned, diffusion, graphs\n",
      "Topic 961 → pertensor, fixedpoint, proxquant, backpropagation, operators\n",
      "Topic 1274 → maml, rapid, reuse, effectiveness, train\n",
      "Topic 971 → freeform, electron, ffjord, reversible, paths\n",
      "Topic 1140 → strokenet, artistic, painting, environment, style\n",
      "Topic 1151 → warm, sgdr, gapaware, staleness, restarts\n",
      "Topic 1204 → identifiability, transformers, verification, robustness, on\n",
      "Topic 1202 → mixout, structbert, finetune, incorporating, structures\n",
      "Topic 1159 → photo, introspective, editing, consistency, regularization\n",
      "Topic 715 → esmaml, metaoptimization, shorthorizon, hessianfree, mcmc\n",
      "Topic 1327 → speed, skimrnn, structuraljumplstm, reading, via\n",
      "Topic 1335 → encourage, eliminate, singularities, connections, skip\n",
      "Topic 1179 → stealing, queryefficient, poisoning, dnn, defenses\n",
      "Topic 1353 → capsules, dotproduct, em, routing, inverted\n",
      "Topic 1161 → carlo, monte, correlated, categorical, autoencoding\n",
      "Topic 1350 → matchlstm, pointer, comprehension, augmented, answer\n",
      "Topic 1348 → l0, regularization, sparse, through, networks\n",
      "Topic 502 → considering, programmatic, probing, trajectories, semantics\n",
      "Topic 1237 → nonlinearities, substantially, create, bad, surfaces\n",
      "Topic 621 → expectationbased, picking, go, objectives, before\n",
      "Topic 597 → recursion, combinator, lattices, programmerinterpreters, procedures\n",
      "Topic 1246 → autoaugment, local, features, improving, robust\n",
      "Topic 1086 → retinal, primate, ganglion, prosthesis, responses\n",
      "Topic 1261 → about, physicsasinversegraphics, objectoriented, physical, interactions\n",
      "Topic 1259 → approximability, vc, quantized, relu, bounds\n",
      "Topic 1257 → incomplete, factorised, misgan, discriminators, observations\n",
      "Topic 1248 → horizon, infinite, infinitehorizon, doubly, offpolicy\n",
      "Topic 1047 → white, channel, noisy, noise, analysis\n",
      "Topic 1336 → spectrum, computation, spectral, under, normalization\n",
      "Topic 1337 → autocurricula, tool, use, environments, disentangling\n",
      "Topic 1311 → deployment, specialize, each, once, bit\n",
      "Topic 857 → maxaffine, parallelizing, spline, length, twin\n",
      "Topic 1218 → explain, efficiently, execution, logic, module\n",
      "Topic 1222 → overlearning, reveals, complexvalued, attributes, obfuscation\n",
      "Topic 1229 → pointprediction, io, fitting, conservative, quantifying\n",
      "Topic 1215 → nas, 0wn, spare, frustratingly, hard\n",
      "Topic 1263 → stiefel, riemannian, cayley, transform, manifold\n",
      "Topic 934 → adaptively, am, inputadaptive, mad, wins\n",
      "Topic 1048 → convexcombinatorial, frankwolfe, whats, mixed, problem\n",
      "Topic 317 → coattention, dcn, coarsegrain, finegrain, multievidence\n",
      "Topic 410 → varibad, bayesadaptive, remapping, very, good\n",
      "Topic 688 → taskfree, uncertaintyguided, nonstationary, dirichlet, continual\n",
      "Topic 852 → dictionary, l4based, noodl, coefficient, dynamical\n",
      "Topic 819 → sketch, drawings, sketchode, strokebased, ssrgnns\n",
      "Topic 805 → skill, dynamicsaware, discovery, cic, lipschitzconstrained\n",
      "Topic 1016 → competition, emergent, capabilities, coordination, compounding\n",
      "Topic 1002 → reset, leave, trace, traces, backtracking\n",
      "Topic 299 → normalizers, sigma, delta, extending, defensive\n",
      "Topic 1101 → transductive, acquisition, bayes, synthetic, metalearning\n",
      "Topic 1133 → grained, nadpex, repeat, fine, repetition\n",
      "Topic 1117 → spectralnet, spectral, unifying, hyperspectral, datadriven\n",
      "Topic 1083 → powersoftwo, relaxed, discretized, nonuniform, discretization\n",
      "Topic 1069 → realistic, comprehensive, compositional, referencelimited, permutation\n",
      "Topic 1089 → music, longterm, steerability, structure, generating\n",
      "Topic 1032 → points, critical, forms, pure, analytical\n",
      "Topic 1033 → deepdsl, compilationbased, compilation, domainspecific, expedited\n",
      "Topic 461 → deductive, expressions, neuralguided, evaluations, program\n",
      "Topic 1308 → prioritized, experience, replay, modelaugmented, forget\n",
      "Topic 1292 → discriminatoractorcritic, addressing, inefficiency, gener, ative\n",
      "Topic 1264 → systematic, situated, required, emergent, scan\n",
      "Topic 1193 → strategies, use, measuring, pretraining, assessment\n",
      "Topic 1352 → formal, finite, automata, languages, representing\n",
      "Topic 258 → texture, bagoflocalfeatures, imagenettrained, works, cnnbased\n",
      "Topic 269 → optimized, contextadaptive, hyperprior, drasic, compression\n",
      "Topic 675 → variations, factors, concepts, controlling, few\n",
      "Topic 609 → hedged, box, embeddings, order, prototype\n",
      "Topic 371 → lossless, hilloc, latentvariable, bits, back\n",
      "Topic 763 → decentralized, arbitrary, communication, bandwidth, communicate\n",
      "Topic 731 → corruptions, integer, common, benchmarking, issues\n",
      "Topic 336 → perturbandparse, cshapley, syntaxdirected, lshapley, structured\n",
      "Topic 424 → deephoyer, sparser, sparsity, singular, tying\n",
      "Topic 404 → skills, motivation, transitional, curricula, selfplay\n",
      "Topic 873 → koopman, operators, biological, modelbased, compositional\n",
      "Topic 472 → storedprogram, kanerva, mogrifier, multigrid, pseudoinverse\n",
      "Topic 605 → nasbench102, nasbench1shot1, scope, reproducible, extending\n",
      "Topic 1010 → distributioninterpolation, off, trade, realism, interpolation\n",
      "Topic 1025 → visceral, riskaversion, physiological, graphenhanced, misaligned\n",
      "Topic 996 → flowqa, grasping, comprehension, conversational, fusionnet\n",
      "Topic 594 → describe, programmer, scenes, learner, neurosymbolic\n",
      "Topic 573 → programs, represent, invocations, hoppity, invocmap\n",
      "Topic 581 → binarized, resnetlike, security, skip, attacking\n",
      "Topic 571 → cgans, graphic, layoutgan, layouts, wireframe\n",
      "Topic 589 → adds, backpropaganda, selforganization, gsnr, truth\n",
      "Topic 936 → unlikelihood, degeneration, curious, skipthought, advcodec\n",
      "Topic 524 → compose, finite, words, sentences, state\n",
      "Topic 538 → sequencetosequence, misesfisher, von, outputs, amortized\n",
      "Topic 119 → diet, fat, metricoptimized, thin, introspectionaccelerating\n",
      "Topic 663 → symmetrydriven, salesperson, plaplacian, condensation, traveling\n",
      "Topic 668 → applicationoriented, forgetting, backpropagated, comprehensive, during\n",
      "Topic 646 → contingencyaware, subjective, sense, open, complex\n",
      "Topic 643 → thump, rattle, swoosh, recomposing, demonstrations\n",
      "Topic 630 → accented, speech, driven, stylization, tts\n",
      "Topic 657 → collision, clevrer, transformationbased, videoflow, video\n",
      "Topic 205 → protein, cryoem, reconstructing, simulator, transferrable\n",
      "Topic 234 → grounded, babyai, domqnet, turker, mechanical\n",
      "Topic 433 → compressed, sensing, nonconvolutional, untrained, subsampling\n",
      "Topic 1112 → theoretic, maxmig, crowds, cotraining, joint\n",
      "Topic 108 → scratch, densitydiversity, n2n, lossconditional, once\n",
      "Topic 259 → nesterov, scale, reject, illegal, intriguing\n",
      "Topic 247 → pacbayesian, noiseresilience, bounds, nonvacuous, spectrallynormalized\n",
      "\n",
      "Most frequent keywords in winning topics:\n",
      "[('', 16), ('openreview', 11), ('neural', 6), ('machine', 5), ('sequence', 5), ('with', 5), ('attention', 4), ('adversarial', 4), ('generative', 4), ('generalization', 4)]\n",
      "\n",
      "Review Length Analysis:\n",
      "- Global average: 2561.2\n",
      "- Accepted: 2537.9\n",
      "- Rejected: 2569.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Extract n-grams (bigrams/trigrams) from titles\n",
    "def extract_ngrams(texts, n=2):\n",
    "    tokens = [re.split(r'\\s+', t.lower()) for t in texts]\n",
    "    ngrams = []\n",
    "    for tok in tokens:\n",
    "        for i in range(len(tok)-n+1):\n",
    "            ngrams.append(tuple(tok[i:i+n]))\n",
    "    return Counter(ngrams)\n",
    "\n",
    "# Function to load all sheets\n",
    "def load_all_sheets(file_path):\n",
    "    xls = pd.ExcelFile(file_path, engine='openpyxl')\n",
    "    all_data = []\n",
    "    for sheet in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet)\n",
    "        if 'title' in df.columns and 'decision' in df.columns:\n",
    "            df['sheet'] = sheet  # Add sheet name for traceability\n",
    "            all_data.append(df)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Function to clean decision values ('Accept' or 'Reject')\n",
    "def clean_decision(decision):\n",
    "    if isinstance(decision, str):\n",
    "        if 'Accept' in decision:\n",
    "            return 'Accept'\n",
    "        elif 'Reject' in decision:\n",
    "            return 'Reject'\n",
    "    return None\n",
    "\n",
    "# Function to extract keywords\n",
    "def extract_keywords(keywords_str):\n",
    "    if isinstance(keywords_str, str):\n",
    "        return [kw.strip() for kw in keywords_str.split(',') if kw.strip()]\n",
    "    return []\n",
    "\n",
    "# Function to count words in title\n",
    "def count_words(title):\n",
    "    return len(str(title).split())\n",
    "\n",
    "# Function to run global topic modeling\n",
    "def run_topic_modeling(titles):\n",
    "    print(\"\\nRunning Global Topic Modeling...\")\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "    model = BERTopic(language=\"english\", vectorizer_model=vectorizer, min_topic_size=10, verbose=False)\n",
    "    topics, probs = model.fit_transform(titles)\n",
    "    print(model.get_topic_info().head(10))\n",
    "    return model\n",
    "\n",
    "# Function to count global keywords\n",
    "def count_global_keywords(df, col='keywords'):\n",
    "    all_keywords = [item for sublist in df[col] for item in sublist]\n",
    "    return Counter(all_keywords)\n",
    "\n",
    "# Helper function to avoid KeyError\n",
    "def safe_explode(df, col):\n",
    "    \"\"\"Internal function to handle optional columns\"\"\"\n",
    "    if col in df.columns:\n",
    "        return df.explode(col)[col].dropna().tolist()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# 1. Prepare data from a sheet\n",
    "def prepare_sheet_data(df_sheet):\n",
    "    print(\"Preparing sheet data...\")\n",
    "    optional_cols = ['title', 'keywords', 'decision', 'rate', 'publish_time', 'review_contentlength']\n",
    "    relevant_cols = [col for col in optional_cols if col in df_sheet.columns]\n",
    "    if 'title' not in df_sheet.columns:\n",
    "        print(\"Warning: Required column 'title' is missing. Cannot proceed.\")\n",
    "        return None\n",
    "    df = df_sheet[relevant_cols].copy()\n",
    "    # Clean keywords\n",
    "    if 'keywords' in df.columns:\n",
    "        df['keywords'] = df['keywords'].astype(str).str.replace('Keywords:###', '', regex=False).str.split(', ')\n",
    "        df['keywords'] = df['keywords'].apply(lambda x: [kw.strip() for kw in x if isinstance(kw, str) and kw.strip()] if isinstance(x, list) else [])\n",
    "    # Create decision_clean only if decision column exists\n",
    "    if 'decision' in df.columns:\n",
    "        df['decision_clean'] = df['decision'].astype(str).str.extract('(Accept|Reject)')\n",
    "    else:\n",
    "        df['decision_clean'] = None\n",
    "        print(\"Warning: Column 'decision' not found. Accept/Reject analysis skipped.\")\n",
    "    print(f\"Data prepared: {len(df)} valid rows.\")\n",
    "    return df\n",
    "\n",
    "# 2. Comparative analysis between accepted and rejected papers\n",
    "def analyze_accepted_vs_rejected(df_prepared, sheet_name, summary_data):\n",
    "    print(f\"\\nCOMPARATIVE ANALYSIS - SHEET '{sheet_name}'\")\n",
    "    has_decision = 'decision_clean' in df_prepared.columns and df_prepared['decision_clean'].notna().any()\n",
    "    if not has_decision:\n",
    "        print(\"No valid decisions ('Accept'/'Reject') found. Skipping Accept/Reject analysis.\")\n",
    "        accepted = pd.DataFrame()\n",
    "        rejected = pd.DataFrame()\n",
    "    else:\n",
    "        accepted = df_prepared[df_prepared['decision_clean'] == 'Accept']\n",
    "        rejected = df_prepared[df_prepared['decision_clean'] == 'Reject']\n",
    "        print(f\"Total papers: {len(df_prepared)}\")\n",
    "        print(f\"Accepted: {len(accepted)} ({len(accepted)/len(df_prepared):.1%})\")\n",
    "        print(f\"Rejected: {len(rejected)} ({len(rejected)/len(df_prepared):.1%})\")\n",
    "\n",
    "    # Initialize dictionary for this sheet\n",
    "    summary_data[sheet_name] = {\n",
    "        \"total\": len(df_prepared),\n",
    "        \"accepted_count\": len(accepted),\n",
    "        \"rejected_count\": len(rejected),\n",
    "        \"all_keywords\": [],\n",
    "        \"accepted_keywords\": [],\n",
    "        \"rejected_keywords\": [],\n",
    "        \"title_lengths\": [],\n",
    "        \"accepted_title_lengths\": [],\n",
    "        \"rejected_title_lengths\": [],\n",
    "        \"titles\": [],\n",
    "        \"accepted_titles\": [],\n",
    "        \"rejected_titles\": [],\n",
    "        \"rates\": [],\n",
    "        \"accepted_rates\": [],\n",
    "        \"rejected_rates\": [],\n",
    "        \"review_lengths\": [],\n",
    "        \"accepted_review_lengths\": [],\n",
    "        \"rejected_review_lengths\": [],\n",
    "        \"submit_dates\": [],\n",
    "        \"accepted_submit_dates\": [],\n",
    "        \"rejected_submit_dates\": [],\n",
    "    }\n",
    "\n",
    "    # Keyword Analysis\n",
    "    if 'keywords' in df_prepared.columns and df_prepared['keywords'].apply(len).sum() > 0:\n",
    "        all_kw = df_prepared.explode('keywords')['keywords'].value_counts()\n",
    "        print(\"\\nTop 10 Most Common Keywords:\")\n",
    "        print(all_kw.head(10))\n",
    "        if has_decision:\n",
    "            acc_kw = accepted.explode('keywords')['keywords'].value_counts().head(10)\n",
    "            rej_kw = rejected.explode('keywords')['keywords'].value_counts().head(10)\n",
    "            print(\"\\nTop Keywords in Accepted Papers:\")\n",
    "            print(acc_kw)\n",
    "            print(\"\\nTop Keywords in Rejected Papers:\")\n",
    "            print(rej_kw)\n",
    "        summary_data[sheet_name][\"all_keywords\"] = safe_explode(df_prepared, 'keywords')\n",
    "        summary_data[sheet_name][\"accepted_keywords\"] = safe_explode(accepted, 'keywords')\n",
    "        summary_data[sheet_name][\"rejected_keywords\"] = safe_explode(rejected, 'keywords')\n",
    "    else:\n",
    "        print(\"\\nNo keywords available for analysis.\")\n",
    "        summary_data[sheet_name][\"all_keywords\"] = []\n",
    "        summary_data[sheet_name][\"accepted_keywords\"] = []\n",
    "        summary_data[sheet_name][\"rejected_keywords\"] = []\n",
    "\n",
    "    # Title Length Analysis\n",
    "    def title_length(title):\n",
    "        return len(str(title).split())\n",
    "\n",
    "    df_prepared['title_len'] = df_prepared['title'].apply(title_length)\n",
    "    mean_len_all = df_prepared['title_len'].mean()\n",
    "    print(f\"\\nAverage number of words in titles: Total={mean_len_all:.1f}\")\n",
    "    summary_data[sheet_name][\"title_lengths\"] = df_prepared['title_len'].tolist()\n",
    "    summary_data[sheet_name][\"titles\"] = df_prepared['title'].astype(str).dropna().tolist()\n",
    "\n",
    "    if has_decision:\n",
    "        mean_len_accept = df_prepared.loc[df_prepared['decision_clean'] == 'Accept', 'title_len'].mean()\n",
    "        mean_len_reject = df_prepared.loc[df_prepared['decision_clean'] == 'Reject', 'title_len'].mean()\n",
    "        print(f\"    Accepted={mean_len_accept:.1f}, Rejected={mean_len_reject:.1f}\")\n",
    "        summary_data[sheet_name][\"accepted_title_lengths\"] = df_prepared.loc[df_prepared['decision_clean'] == 'Accept', 'title_len'].tolist()\n",
    "        summary_data[sheet_name][\"rejected_title_lengths\"] = df_prepared.loc[df_prepared['decision_clean'] == 'Reject', 'title_len'].tolist()\n",
    "        summary_data[sheet_name][\"accepted_titles\"] = accepted['title'].astype(str).dropna().tolist()\n",
    "        summary_data[sheet_name][\"rejected_titles\"] = rejected['title'].astype(str).dropna().tolist()\n",
    "\n",
    "    # Average Rating Analysis\n",
    "    if 'rate' in df_prepared.columns:\n",
    "        df_prepared['rate'] = pd.to_numeric(df_prepared['rate'], errors='coerce')\n",
    "        mean_rate_all = df_prepared['rate'].mean()\n",
    "        print(f\"\\nAverage rating: Total={mean_rate_all:.1f}\")\n",
    "        summary_data[sheet_name][\"rates\"] = df_prepared['rate'].dropna().tolist()\n",
    "        if has_decision:\n",
    "            mean_rate_accept = df_prepared.loc[df_prepared['decision_clean'] == 'Accept', 'rate'].mean()\n",
    "            mean_rate_reject = df_prepared.loc[df_prepared['decision_clean'] == 'Reject', 'rate'].mean()\n",
    "            print(f\"    Accepted={mean_rate_accept:.1f}, Rejected={mean_rate_reject:.1f}\")\n",
    "            summary_data[sheet_name][\"accepted_rates\"] = df_prepared.loc[df_prepared['decision_clean'] == 'Accept', 'rate'].dropna().tolist()\n",
    "            summary_data[sheet_name][\"rejected_rates\"] = df_prepared.loc[df_prepared['decision_clean'] == 'Reject', 'rate'].dropna().tolist()\n",
    "    else:\n",
    "        print(\"\\nColumn 'rate' not present. Rating analysis skipped.\")\n",
    "\n",
    "    # Review content length analysis\n",
    "    if 'review_contentlength' in df_prepared.columns:\n",
    "        df_prepared['review_contentlength'] = pd.to_numeric(df_prepared['review_contentlength'], errors='coerce')\n",
    "        summary_data[sheet_name][\"review_lengths\"] = df_prepared['review_contentlength'].dropna().tolist()\n",
    "        if has_decision:\n",
    "            summary_data[sheet_name][\"accepted_review_lengths\"] = df_prepared.loc[df_prepared['decision_clean'] == 'Accept', 'review_contentlength'].dropna().tolist()\n",
    "            summary_data[sheet_name][\"rejected_review_lengths\"] = df_prepared.loc[df_prepared['decision_clean'] == 'Reject', 'review_contentlength'].dropna().tolist()\n",
    "\n",
    "    # Submission date analysis\n",
    "    if 'publish_time' in df_prepared.columns:\n",
    "        df_prepared['submit_date'] = pd.to_datetime(df_prepared['publish_time'].str.split(' ').str[0], errors='coerce')\n",
    "        summary_data[sheet_name][\"submit_dates\"] = df_prepared['submit_date'].dropna().tolist()\n",
    "        if has_decision:\n",
    "            summary_data[sheet_name][\"accepted_submit_dates\"] = df_prepared.loc[df_prepared['decision_clean'] == 'Accept', 'submit_date'].dropna().tolist()\n",
    "            summary_data[sheet_name][\"rejected_submit_dates\"] = df_prepared.loc[df_prepared['decision_clean'] == 'Reject', 'submit_date'].dropna().tolist()\n",
    "\n",
    "    return accepted, rejected\n",
    "\n",
    "# 3. Topic Modeling on Titles\n",
    "def topic_modeling_titles_for_sheet(accepted, rejected, sheet_name):\n",
    "    print(f\"\\nTopic Modeling on Titles - SHEET '{sheet_name}'\")\n",
    "    min_docs_for_topic_modeling = 5\n",
    "\n",
    "    def run_topic_model(titles, label):\n",
    "        if len(titles) < min_docs_for_topic_modeling:\n",
    "            print(f\"Fewer than {min_docs_for_topic_modeling} titles for {label}. Skipped.\")\n",
    "            return\n",
    "        try:\n",
    "            model = BERTopic(language=\"english\", min_topic_size=min_docs_for_topic_modeling, verbose=False)\n",
    "            topics, _ = model.fit_transform(titles)\n",
    "            info = model.get_topic_info().head(6)\n",
    "            print(f\"\\nTop Topics - {label}:\")\n",
    "            print(info)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in topic modeling for {label}: {e}\")\n",
    "\n",
    "    if not accepted.empty and 'title' in accepted.columns:\n",
    "        titles = accepted['title'].astype(str).dropna().tolist()\n",
    "        run_topic_model(titles, \"Accepted\")\n",
    "    if not rejected.empty and 'title' in rejected.columns:\n",
    "        titles = rejected['title'].astype(str).dropna().tolist()\n",
    "        run_topic_model(titles, \"Rejected\")\n",
    "\n",
    "# 4. Global Aggregated Analysis\n",
    "def global_analysis(summary_data):\n",
    "    print(\"\\nGlobal Aggregated Analysis Across All Sheets\")\n",
    "    all_global_kw = []\n",
    "    acc_global_kw = []\n",
    "    rej_global_kw = []\n",
    "    all_global_titles = []\n",
    "    acc_global_titles = []\n",
    "    rej_global_titles = []\n",
    "    all_global_rates = []\n",
    "    acc_global_rates = []\n",
    "    rej_global_rates = []\n",
    "    title_lengths_all = []\n",
    "    title_lengths_acc = []\n",
    "    title_lengths_rej = []\n",
    "    review_lengths_all = []\n",
    "    review_lengths_acc = []\n",
    "    review_lengths_rej = []\n",
    "    submit_dates_all = []\n",
    "    submit_dates_acc = []\n",
    "    submit_dates_rej = []\n",
    "\n",
    "    for sheet in summary_data:\n",
    "        data = summary_data[sheet]\n",
    "        all_global_kw.extend(data[\"all_keywords\"])\n",
    "        acc_global_kw.extend(data[\"accepted_keywords\"])\n",
    "        rej_global_kw.extend(data[\"rejected_keywords\"])\n",
    "        all_global_titles.extend(data[\"titles\"])\n",
    "        acc_global_titles.extend(data[\"accepted_titles\"])\n",
    "        rej_global_titles.extend(data[\"rejected_titles\"])\n",
    "        all_global_rates.extend(data[\"rates\"])\n",
    "        acc_global_rates.extend(data[\"accepted_rates\"])\n",
    "        rej_global_rates.extend(data[\"rejected_rates\"])\n",
    "        title_lengths_all.extend(data[\"title_lengths\"])\n",
    "        title_lengths_acc.extend(data[\"accepted_title_lengths\"])\n",
    "        title_lengths_rej.extend(data[\"rejected_title_lengths\"])\n",
    "        review_lengths_all.extend(data[\"review_lengths\"])\n",
    "        review_lengths_acc.extend(data[\"accepted_review_lengths\"])\n",
    "        review_lengths_rej.extend(data[\"rejected_review_lengths\"])\n",
    "        submit_dates_all.extend(data[\"submit_dates\"])\n",
    "        submit_dates_acc.extend(data[\"accepted_submit_dates\"])\n",
    "        submit_dates_rej.extend(data[\"rejected_submit_dates\"])\n",
    "\n",
    "    # Global Statistics\n",
    "    print(\"\\nGlobal Statistics:\")\n",
    "    print(f\"Total papers: {len(all_global_titles)}\")\n",
    "    print(f\"Average number of words in titles: {np.mean(title_lengths_all):.1f}\")\n",
    "    if title_lengths_acc:\n",
    "        print(f\"Average number of words in accepted titles: {np.mean(title_lengths_acc):.1f}\")\n",
    "    if title_lengths_rej:\n",
    "        print(f\"Average number of words in rejected titles: {np.mean(title_lengths_rej):.1f}\")\n",
    "\n",
    "    # Ratings\n",
    "    if all_global_rates:\n",
    "        print(f\"Global average rating: {np.mean(all_global_rates):.1f}\")\n",
    "        if acc_global_rates:\n",
    "            print(f\"Average rating for accepted papers: {np.mean(acc_global_rates):.1f}\")\n",
    "        if rej_global_rates:\n",
    "            print(f\"Average rating for rejected papers: {np.mean(rej_global_rates):.1f}\")\n",
    "\n",
    "    # Global Keywords\n",
    "    print(\"\\nTop 10 Global Keywords:\")\n",
    "    print(Counter(all_global_kw).most_common(10))\n",
    "    print(\"\\nTop 10 Keywords in Accepted Papers:\")\n",
    "    print(Counter(acc_global_kw).most_common(10))\n",
    "    print(\"\\nTop 10 Keywords in Rejected Papers:\")\n",
    "    print(Counter(rej_global_kw).most_common(10))\n",
    "\n",
    "    # N-gram Analysis\n",
    "    print(\"\\nMost Common Bigrams in Titles:\")\n",
    "    print(extract_ngrams(all_global_titles, n=2).most_common(10))\n",
    "    print(\"\\nMost Common Trigrams in Titles:\")\n",
    "    print(extract_ngrams(all_global_titles, n=3).most_common(10))\n",
    "\n",
    "    # Global Topic Modeling\n",
    "    print(\"\\nGlobal Topic Modeling on All Titles:\")\n",
    "    if len(all_global_titles) >= 5:\n",
    "        model = BERTopic(language=\"english\", min_topic_size=5, verbose=False)\n",
    "        topics, _ = model.fit_transform(all_global_titles)\n",
    "        print(model.get_topic_info().head(6))\n",
    "    else:\n",
    "        print(\"Not enough titles for global topic modeling.\")\n",
    "\n",
    "    # Topic vs Decision\n",
    "    if len(all_global_titles) >= 5 and len(acc_global_titles) > 0 and len(rej_global_titles) > 0:\n",
    "        print(\"\\nGlobal Topic Modeling + Topic-Decision Association:\")\n",
    "\n",
    "        titles = acc_global_titles + rej_global_titles\n",
    "        decisions = ['accept'] * len(acc_global_titles) + ['reject'] * len(rej_global_titles)\n",
    "\n",
    "        df_global = pd.DataFrame({\n",
    "            'title': titles,\n",
    "            'decision': decisions\n",
    "        })\n",
    "\n",
    "        model = BERTopic(language=\"english\", min_topic_size=5, verbose=False)\n",
    "        topics, probs = model.fit_transform(df_global['title'])\n",
    "        df_global['topic'] = topics\n",
    "\n",
    "        topic_decisions = df_global.groupby('topic')['decision'].value_counts(normalize=True).unstack(fill_value=0).sort_values(by='accept', ascending=False)\n",
    "        print(topic_decisions)\n",
    "\n",
    "        print(\"\\nTop Topics with Acceptance Keywords:\")\n",
    "        for topic_id in topic_decisions.index[:5]:\n",
    "            keywords = model.get_topic(topic_id)\n",
    "            if isinstance(keywords, list):\n",
    "                keyword_list = \", \".join([word for word, _ in keywords[:5]])\n",
    "            else:\n",
    "                keyword_list = \"N/A\"\n",
    "            print(f\"Topic {topic_id}: {keyword_list}\")\n",
    "\n",
    "        topic_keywords = {topic: model.get_topic(topic) for topic in df_global['topic'].unique()}\n",
    "\n",
    "        high_accept_topics = topic_decisions[topic_decisions['accept'] > 0.7].index.tolist()\n",
    "        print(\"\\nKeywords associated with high acceptance topics:\")\n",
    "        success_keywords = []\n",
    "        for topic_id in high_accept_topics:\n",
    "            keywords = model.get_topic(topic_id)\n",
    "            if isinstance(keywords, list):\n",
    "                words = [word for word, _ in keywords]\n",
    "                success_keywords.extend(words)\n",
    "                keyword_line = \", \".join(words[:5])\n",
    "            else:\n",
    "                keyword_line = \"N/A\"\n",
    "            print(f\"Topic {topic_id} → {keyword_line}\")\n",
    "\n",
    "        print(\"\\nMost frequent keywords in winning topics:\")\n",
    "        print(Counter(success_keywords).most_common(10))\n",
    "    else:\n",
    "        print(\"Not enough data for Topic vs Decision analysis.\")\n",
    "\n",
    "    # Review Length Analysis\n",
    "    if review_lengths_all:\n",
    "        print(\"\\nReview Length Analysis:\")\n",
    "        print(f\"- Global average: {np.mean(review_lengths_all):.1f}\")\n",
    "        if review_lengths_acc:\n",
    "            print(f\"- Accepted: {np.mean(review_lengths_acc):.1f}\")\n",
    "        if review_lengths_rej:\n",
    "            print(f\"- Rejected: {np.mean(review_lengths_rej):.1f}\")\n",
    "\n",
    "    # Temporal Analysis\n",
    "    if submit_dates_all:\n",
    "        print(\"\\nTemporal Analysis:\")\n",
    "        submit_df = pd.DataFrame({'date': submit_dates_all})\n",
    "        submit_df['month_year'] = pd.to_datetime(submit_df['date']).dt.to_period('M')\n",
    "        print(submit_df['month_year'].value_counts().sort_index())\n",
    "        if submit_dates_acc and submit_dates_rej:\n",
    "            accept_df = pd.DataFrame({'date': submit_dates_acc, 'type': 'accept'})\n",
    "            reject_df = pd.DataFrame({'date': submit_dates_rej, 'type': 'reject'})\n",
    "            combined = pd.concat([accept_df, reject_df])\n",
    "            monthly = combined.resample('M', on='date').value_counts().unstack(fill_value=0)\n",
    "            print(monthly)\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"/content/drive/MyDrive/KnowledgeDiscoveryAndPatternExtraction/cleaned_dataset.xlsx\"\n",
    "    sheet_names = None\n",
    "    try:\n",
    "        xls = pd.ExcelFile(file_path, engine='openpyxl')\n",
    "        sheet_names = xls.sheet_names\n",
    "        print(f\"\\nFile loaded successfully. Available sheets: {sheet_names}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found.\")\n",
    "        exit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening Excel file: {e}\")\n",
    "        exit()\n",
    "\n",
    "    summary_data = {}  # To collect aggregated data\n",
    "\n",
    "    for sheet_name in sheet_names:\n",
    "        print(f\"\\n{'='*40}\\nStarting analysis: {sheet_name}\\n{'='*40}\")\n",
    "        df_sheet = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "        if df_sheet.empty:\n",
    "            print(f\"Sheet '{sheet_name}' is empty. Skipping.\")\n",
    "            continue\n",
    "        df_prepared = prepare_sheet_data(df_sheet)\n",
    "        if df_prepared is None or df_prepared.empty:\n",
    "            print(f\"No valid data for sheet '{sheet_name}'.\")\n",
    "            continue\n",
    "        accepted, rejected = analyze_accepted_vs_rejected(df_prepared, sheet_name, summary_data)\n",
    "        topic_modeling_titles_for_sheet(accepted, rejected, sheet_name)\n",
    "        print(f\"{'='*40}\\nFinished analysis: {sheet_name}\\n{'='*40}\")\n",
    "\n",
    "    # Final aggregated analysis\n",
    "    if summary_data:\n",
    "        global_analysis(summary_data)\n",
    "    else:\n",
    "        print(\"No useful data for aggregated analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpekmQMroILW"
   },
   "source": [
    "# Paper Acceptance Analysis\n",
    "**Objective:** Identify patterns and best practices from a dataset of accepted and rejected scientific papers to provide actionable insights for improving paper quality and increasing acceptance rates.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Dataset Overview\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Total Papers Analyzed | 23,269 |\n",
    "| Accepted Papers | 7,435 (31.9%) |\n",
    "| Rejected Papers | 15,834 (68.1%) |\n",
    "| Average Word Count in Titles | 9.3 words |\n",
    "| - Accepted | 9.4 words |\n",
    "| - Rejected | 9.6 words |\n",
    "| Average Rating | 5.0 |\n",
    "| - Accepted | 6.5 |\n",
    "| - Rejected | 4.1 |\n",
    "\n",
    "This section provides a general summary of the dataset, including the total number of papers analyzed, acceptance and rejection rates, average title length, and average ratings. It gives context and scale to the analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Key Insights: What Works, What Doesn’t\n",
    "\n",
    "### Topics Associated with High Acceptance Rates\n",
    "\n",
    "The following topics show **100% acceptance rates** based on topic modeling:\n",
    "\n",
    "| Topic ID | Keywords |\n",
    "|----------|----------|\n",
    "| 616 | recursion, combinator, lattices, programmerinterpreters |\n",
    "| 1320 | explain, execution, logic, module |\n",
    "| 673 | subset, homotopy, correspondence, transport |\n",
    "| 1317 | warm, sgdr, gapaware, staleness |\n",
    "| 1325 | retinal, prosthesis, ganglion, primate |\n",
    "\n",
    "---\n",
    "\n",
    "### Keywords Found in Accepted Papers\n",
    "\n",
    "| Keyword | Frequency |\n",
    "|--------|-----------|\n",
    "| Deep learning | 548 |\n",
    "| Reinforcement Learning | 281 |\n",
    "| Natural Language Processing | 138 |\n",
    "| Unsupervised Learning | 135 |\n",
    "| Optimization | 121 |\n",
    "| Representation Learning | 106 |\n",
    "\n",
    "---\n",
    "\n",
    "### Keywords Commonly Found in Rejected Papers\n",
    "\n",
    "| Keyword | Frequency |\n",
    "|--------|-----------|\n",
    "| Deep learning | 713 |\n",
    "| deep learning | 713 |\n",
    "| representation learning | 278 |\n",
    "| self-supervised learning | 36 |\n",
    "\n",
    "---\n",
    "\n",
    "Highlights the topics and keywords most strongly associated with accepted or rejected papers. This helps identify trending and well-received research areas versus overused or less-impactful terms.\n",
    "\n",
    "## 3. Title Structure & Length\n",
    "\n",
    "- **Average title length**: 9.3 words  \n",
    "- **Accepted papers**: ~9.4 words  \n",
    "- **Rejected papers**: ~9.6 words  \n",
    "\n",
    "### Most Common N-Grams in Titles:\n",
    "- **Bigrams**: `neural networks`, `learning with`, `deep learning`\n",
    "- **Trigrams**: `deep neural networks`, `generative adversarial networks`, `graph neural networks`\n",
    "\n",
    "Analyzes the average length and common linguistic patterns (bigrams and trigrams) found in paper titles. Offers guidance on how to craft effective, standards-aligned titles that resonate with reviewers.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Quality = Acceptance\n",
    "\n",
    "There is a **strong correlation between high ratings and acceptance**:\n",
    "- **Accepted papers average rating**: 6.5\n",
    "- **Rejected papers average rating**: 4.1\n",
    "\n",
    "Demonstrates the strong correlation between higher average ratings and paper acceptance. Emphasizes that perceived quality — through clarity, rigor, and relevance — significantly impacts the likelihood of acceptance.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Review Length\n",
    "\n",
    "| Category | Average Length (characters) |\n",
    "|---------|-----------------------------|\n",
    "| Global | 2561 |\n",
    "| Accepted | 2538 |\n",
    "| Rejected | 2569 |\n",
    "\n",
    "Compares the average length of peer reviews across accepted and rejected papers. Suggests that review length is not a decisive factor in acceptance, but rather the content and strength of the feedback matters more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdpHi5ZSoNZI"
   },
   "source": [
    "# Pairwise comparison of papers through LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ku-JxEcfoOrC"
   },
   "outputs": [],
   "source": [
    "def clean_titles_of_openreview(sheets):\n",
    "    \"\"\"\n",
    "    Removes the word 'openreview' from the 'title' column in all sheets.\n",
    "\n",
    "    Parameters:\n",
    "        sheets (dict): Dictionary of DataFrames keyed by sheet name.\n",
    "\n",
    "    Returns:\n",
    "        dict: Cleaned sheets with updated titles.\n",
    "    \"\"\"\n",
    "    cleaned = {}\n",
    "\n",
    "    for sheet_name, df in sheets.items():\n",
    "        df = df.copy()\n",
    "        df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "        if 'title' in df.columns:\n",
    "            df['title'] = df['title'].astype(str).str.replace(r'openreview', '', case=False, regex=True).str.strip()\n",
    "\n",
    "        cleaned[sheet_name] = df\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "sheets = clean_titles_of_openreview(sheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No6_nS7S50mN"
   },
   "source": [
    "In this section, we explore how large language models (LLMs) can be used to manually extract useful insights from research papers. Specifically, we focus on both accepted and rejected papers from the dataset to identify patterns or information that could contribute to writing stronger submissions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPBuH4UT52TM",
    "outputId": "bbcb1650-3f76-4aac-eb13-3fbbf02db1b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 titles in multiple sheets:\n",
      "- 'Data augmentation instead of explicit regularization |' appears in: ['Sheet2', 'Sheet4']\n",
      "- 'Efficient Exploration through Bayesian Deep Q-Networks |' appears in: ['Sheet2', 'Sheet3']\n",
      "- 'Graph2Seq: Scalable Learning Dynamics for Graphs |' appears in: ['Sheet2', 'Sheet3']\n",
      "- 'Massively Parallel Hyperparameter Tuning |' appears in: ['Sheet2', 'Sheet3']\n",
      "- 'Open Loop Hyperparameter Optimization and Determinantal Point Processes |' appears in: ['Sheet2', 'Sheet3']\n",
      "- 'Value Propagation Networks |' appears in: ['Sheet2', 'Sheet3']\n",
      "- 'withdrawn |' appears in: ['Sheet2', 'Sheet3']\n",
      "- 'Dataset Distillation |' appears in: ['Sheet3', 'Sheet4']\n",
      "- 'Deep Imitative Models for Flexible Inference, Planning, and Control |' appears in: ['Sheet3', 'Sheet4']\n",
      "- 'Double Neural Counterfactual Regret Minimization |' appears in: ['Sheet3', 'Sheet4']\n",
      "- 'Pushing the bounds of dropout |' appears in: ['Sheet3', 'Sheet4']\n",
      "- 'Unified recurrent network for many feature types |' appears in: ['Sheet3', 'Sheet4']\n",
      "- 'Unsupervised Meta-Learning for Reinforcement Learning |' appears in: ['Sheet3', 'Sheet4']\n",
      "- 'Weakly-supervised Knowledge Graph Alignment with Adversarial Learning |' appears in: ['Sheet3', 'Sheet4']\n",
      "- 'max-affine spline insights into deep network pruning' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'class-weighted evaluation metrics for imbalanced data classification' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'autonomous learning of object-centric abstractions for high-level planning' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'towards understanding label smoothing' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'apollo: an adaptive parameter-wised diagonal quasi-newton method for nonconvex stochastic optimization' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'poisoned classifiers are not only backdoored, they are fundamentally broken' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'learning to actively learn: a robust approach' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'on the certified robustness for ensemble models and beyond' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'ariel: volume coding for sentence generation comparisons' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'novel policy seeking with constrained optimization' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'almost tight l0-norm certified robustness of top-k predictions against adversarial perturbations' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'is deeper better? it depends on locality of relevant features' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'learning to solve multi-robot task allocation with a covariant-attention based neural architecture' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'learning-augmented sketches for hessians' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'stability analysis of sgd through the normalized loss function' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'optimization variance: exploring generalization properties of dnns' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'concentric spherical gnn for 3d representation learning' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'l2e: learning to exploit your opponent' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'classify and generate reciprocally: simultaneous positive-unlabelled learning and conditional generation with extra data' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'augmented sliced wasserstein distances' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'mqtransformer: multi-horizon forecasts with context dependent and feedback-aware attention' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'wiring up vision: minimizing supervised synaptic updates needed to produce a primate ventral stream' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'neurosymbolic deep generative models for sequence data with relational constraints' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'direct evolutionary optimization of variational autoencoders with binary latents' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'relational learning with variational bayes' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'bridging the gap: providing post-hoc symbolic explanations for sequential decision-making problems with inscrutable representations' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'open-world semi-supervised learning' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'align-rudder: learning from few demonstrations by reward redistribution' appears in: ['Sheet5', 'Sheet6']\n",
      "- 'information condensing active learning' appears in: ['Sheet5', 'Sheet6']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def find_titles_in_multiple_sheets(sheets):\n",
    "    \"\"\"\n",
    "    Identifies paper titles that appear in more than one sheet.\n",
    "\n",
    "    Parameters:\n",
    "        sheets (dict): Dictionary of DataFrames keyed by sheet name.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary mapping each duplicate title to the list of sheet names it appears in.\n",
    "    \"\"\"\n",
    "    title_map = defaultdict(set)\n",
    "\n",
    "    for sheet_name, df in sheets.items():\n",
    "        df.columns = df.columns.str.lower().str.strip()\n",
    "        if 'title' not in df.columns:\n",
    "            continue\n",
    "\n",
    "        titles = df['title'].dropna().str.strip().unique()\n",
    "        for title in titles:\n",
    "            title_map[title].add(sheet_name)\n",
    "\n",
    "    duplicates = {title: sorted(list(sheet_names)) for title, sheet_names in title_map.items() if len(sheet_names) > 1}\n",
    "    return duplicates\n",
    "\n",
    "# Example usage:\n",
    "duplicate_titles = find_titles_in_multiple_sheets(sheets)\n",
    "print(f\"Found {len(duplicate_titles)} titles in multiple sheets:\")\n",
    "for title, sheet_names in duplicate_titles.items():\n",
    "    print(f\"- '{title}' appears in: {sheet_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkuUViiD54XP"
   },
   "source": [
    "Since only sheet 5 and 6 has links to the submitted paper we can just focus on those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aocjs0vO57Ae",
    "outputId": "0b6f553e-30af-4f7d-cd6c-a864c06dba2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common titles between Sheet5 and Sheet6: 29\n",
      "- concentric spherical gnn for 3d representation learning\n",
      "- direct evolutionary optimization of variational autoencoders with binary latents\n",
      "- poisoned classifiers are not only backdoored, they are fundamentally broken\n",
      "- learning to actively learn: a robust approach\n",
      "- max-affine spline insights into deep network pruning\n",
      "- almost tight l0-norm certified robustness of top-k predictions against adversarial perturbations\n",
      "- is deeper better? it depends on locality of relevant features\n",
      "- towards understanding label smoothing\n",
      "- bridging the gap: providing post-hoc symbolic explanations for sequential decision-making problems with inscrutable representations\n",
      "- align-rudder: learning from few demonstrations by reward redistribution\n",
      "- mqtransformer: multi-horizon forecasts with context dependent and feedback-aware attention\n",
      "- novel policy seeking with constrained optimization\n",
      "- learning to solve multi-robot task allocation with a covariant-attention based neural architecture\n",
      "- information condensing active learning\n",
      "- classify and generate reciprocally: simultaneous positive-unlabelled learning and conditional generation with extra data\n",
      "- wiring up vision: minimizing supervised synaptic updates needed to produce a primate ventral stream\n",
      "- stability analysis of sgd through the normalized loss function\n",
      "- autonomous learning of object-centric abstractions for high-level planning\n",
      "- l2e: learning to exploit your opponent\n",
      "- apollo: an adaptive parameter-wised diagonal quasi-newton method for nonconvex stochastic optimization\n",
      "- on the certified robustness for ensemble models and beyond\n",
      "- relational learning with variational bayes\n",
      "- ariel: volume coding for sentence generation comparisons\n",
      "- optimization variance: exploring generalization properties of dnns\n",
      "- neurosymbolic deep generative models for sequence data with relational constraints\n",
      "- learning-augmented sketches for hessians\n",
      "- class-weighted evaluation metrics for imbalanced data classification\n",
      "- augmented sliced wasserstein distances\n",
      "- open-world semi-supervised learning\n"
     ]
    }
   ],
   "source": [
    "def find_common_titles_between_sheets(sheets, sheet1_name, sheet2_name):\n",
    "    \"\"\"\n",
    "    Finds papers with the same title in two specified sheets.\n",
    "\n",
    "    Parameters:\n",
    "        sheets (dict): Dictionary of DataFrames keyed by sheet name.\n",
    "        sheet1_name (str): Name of the first sheet.\n",
    "        sheet2_name (str): Name of the second sheet.\n",
    "\n",
    "    Returns:\n",
    "        list: List of titles common to both sheets.\n",
    "    \"\"\"\n",
    "    df1 = sheets[sheet1_name].copy()\n",
    "    df2 = sheets[sheet2_name].copy()\n",
    "\n",
    "    df1.columns = df1.columns.str.lower().str.strip()\n",
    "    df2.columns = df2.columns.str.lower().str.strip()\n",
    "\n",
    "    titles1 = df1['title'].dropna().str.strip().unique()\n",
    "    titles2 = df2['title'].dropna().str.strip().unique()\n",
    "\n",
    "    common_titles = list(set(titles1).intersection(titles2))\n",
    "    return common_titles\n",
    "\n",
    "# Example usage:\n",
    "common_titles = find_common_titles_between_sheets(sheets, 'Sheet5', 'Sheet6')\n",
    "print(f\"Common titles between Sheet5 and Sheet6: {len(common_titles)}\")\n",
    "for title in common_titles:\n",
    "    print(\"-\", title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eyIulJcc6AQh"
   },
   "outputs": [],
   "source": [
    "def extract_title_info_from_sheets(sheets, titles):\n",
    "    \"\"\"\n",
    "    For each given title, find and collect its rows from all sheets where it appears.\n",
    "\n",
    "    Parameters:\n",
    "        sheets (dict): Dictionary of DataFrames keyed by sheet name.\n",
    "        titles (list or set): List of titles to search for.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary where keys are titles and values are lists of (sheet_name, DataFrame) pairs.\n",
    "    \"\"\"\n",
    "    title_info = {}\n",
    "    normalized_titles = {t.strip().lower(): t for t in titles}  # Normalize for matching, preserve original\n",
    "\n",
    "    for norm_title, original_title in normalized_titles.items():\n",
    "        matching_entries = []\n",
    "        for sheet_name, df in sheets.items():\n",
    "            df.columns = df.columns.str.lower().str.strip()\n",
    "            if 'title' not in df.columns:\n",
    "                continue\n",
    "\n",
    "            # Safe matching without index misalignment\n",
    "            mask = df['title'].astype(str).str.strip().str.lower() == norm_title\n",
    "            matches = df[mask]\n",
    "\n",
    "            if not matches.empty:\n",
    "                matching_entries.append((sheet_name, matches))\n",
    "\n",
    "        if matching_entries:\n",
    "            title_info[original_title] = matching_entries\n",
    "\n",
    "    return title_info\n",
    "\n",
    "# Example usage:\n",
    "# titles = list of duplicate paper titles\n",
    "info_by_title = extract_title_info_from_sheets(sheets, common_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXvsnrTs56f0"
   },
   "source": [
    "Let's filter on the accepted papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3HG6a_N6Cw-",
    "outputId": "d31f685b-0616-4b70-dba1-85beab91c48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'almost tight l0-norm certified robustness of top-k predictions against adversarial perturbations' accepted in sheets: ['Sheet5']\n",
      "✅ 'bridging the gap: providing post-hoc symbolic explanations for sequential decision-making problems with inscrutable representations' accepted in sheets: ['Sheet5']\n",
      "✅ 'wiring up vision: minimizing supervised synaptic updates needed to produce a primate ventral stream' accepted in sheets: ['Sheet5']\n",
      "✅ 'autonomous learning of object-centric abstractions for high-level planning' accepted in sheets: ['Sheet5']\n",
      "✅ 'on the certified robustness for ensemble models and beyond' accepted in sheets: ['Sheet5']\n",
      "✅ 'relational learning with variational bayes' accepted in sheets: ['Sheet5']\n",
      "✅ 'augmented sliced wasserstein distances' accepted in sheets: ['Sheet5']\n",
      "✅ 'open-world semi-supervised learning' accepted in sheets: ['Sheet5']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_accepted(decision):\n",
    "    \"\"\"\n",
    "    Determines if a decision value indicates acceptance.\n",
    "    Accepts variants like strings (\"accept\", \"Accept (Poster)\") or numbers (1, np.int64(1)).\n",
    "    \"\"\"\n",
    "    if isinstance(decision, (int, np.integer)):\n",
    "        return decision == 1\n",
    "    elif isinstance(decision, str):\n",
    "        return 'accept' in decision.lower()\n",
    "    return False\n",
    "\n",
    "def filter_accepted_papers_with_sheets(info_by_title):\n",
    "    \"\"\"\n",
    "    Filters for accepted papers and lists the sheets where they were accepted.\n",
    "\n",
    "    Parameters:\n",
    "        info_by_title (dict): Dictionary of (title -> [(sheet_name, df), ...])\n",
    "\n",
    "    Returns:\n",
    "        dict: title -> list of sheet names where paper was accepted\n",
    "    \"\"\"\n",
    "    accepted = {}\n",
    "\n",
    "    for title, entries in info_by_title.items():\n",
    "        accepted_sheets = []\n",
    "        for sheet_name, df in entries:\n",
    "            df.columns = df.columns.str.lower().str.strip()\n",
    "            if 'decision' in df.columns:\n",
    "                decisions = df['decision']\n",
    "                if any(is_accepted(val) for val in decisions):\n",
    "                    accepted_sheets.append(sheet_name)\n",
    "        if accepted_sheets:\n",
    "            accepted[title] = accepted_sheets\n",
    "\n",
    "    return accepted\n",
    "\n",
    "# Example usage:\n",
    "accepted_titles_with_sheets = filter_accepted_papers_with_sheets(info_by_title)\n",
    "\n",
    "# Print results\n",
    "for title, sheets in accepted_titles_with_sheets.items():\n",
    "    print(f\"✅ '{title}' accepted in sheets: {sheets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G_1vtYr6PmD"
   },
   "source": [
    "We report here all the links for simplicity:\n",
    "\n",
    "| Title | Link of Rejected (sheet 6) | Link of Accepted (sheet 5) |\n",
    "|--------|-------|---------|\n",
    "| Relational Learning with Variational Bayes | https://openreview.net/forum?id=PiKUvDj5jyN | https://openreview.net/forum?id=Az-7gJc6lpr |\n",
    "| On the Certified Robustness for Ensemble Models and Beyond  | https://openreview.net/forum?id=IUYthV32lbK | https://openreview.net/forum?id=tUa4REjGjTf |\n",
    "| Autonomous Learning of Object-Centric Abstractions for High-Level Planning  | https://openreview.net/forum?id=PmVfnB0nkqr | https://openreview.net/forum?id=rrWeE9ZDw_ |\n",
    "| Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations | https://openreview.net/forum?id=iOVomQW073 | https://openreview.net/forum?id=gJLEXy3ySpu |\n",
    "| Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Inscrutable Representations | https://openreview.net/forum?id=TETmEkko7e5 | https://openreview.net/forum?id=o-1v9hdSult |\n",
    "| Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream  | https://openreview.net/forum?id=5i4vRgoZauw | https://openreview.net/forum?id=g1SzIRLQXMM |\n",
    "| Open-world Semi-supervised Learning  | https://openreview.net/forum?id=6VhmvP7XZue | https://openreview.net/forum?id=O-r8LOR-CCA |\n",
    "| Augmented Sliced Wasserstein Distances  | https://openreview.net/forum?id=ot9bYHvuULl | https://openreview.net/forum?id=iMqTLyfwnOO |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g07sxcesZYuZ"
   },
   "source": [
    "After retrieving all the papers, we asked to the GPT-4o model to perform a **comparative analysis** between the accepted and rejected versions. In particular we asked:\n",
    "\n",
    "\n",
    "\n",
    "1. **Abstract Comparison**: How did the abstracts differ in clarity, structure, or emphasis? Which keywords or framing might have made the accepted version stronger?\n",
    "2. **Introduction & Motivation**: Was the problem stated more clearly or urgently in the accepted paper?\n",
    "Did the rejected version fail to establish novelty or significance?\n",
    "3. **Related Work**: Was the literature coverage more thorough or recent in the accepted version?\n",
    "Did it better position the paper within the current research landscape?\n",
    "4. **Methodology & Experiments**:\n",
    "Were experiments more comprehensive, reproducible, or better visualized?\n",
    "Did the rejected paper lack clarity or detail in implementation?\n",
    "5. **Results & Discussion**:\n",
    "Was there more rigorous statistical analysis?\n",
    "Was the accepted version better at interpreting results or anticipating criticism?\n",
    "6. **Conclusion**: Did it better highlight contributions or suggest compelling future work?\n",
    "\n",
    "We have also asked to evaluate the **quantitative and structureal insights**:\n",
    "1. **Length Analysis**:\n",
    "Word counts per section: Were key sections longer or more detailed in the accepted version?\n",
    "2. **Figure/Table Use**: More/better diagrams, clearer presentation of data?\n",
    "3. **Citation Density** Did the accepted version cite more or higher-impact works?\n",
    "\n",
    "Another aspect in the analysis was the **style and writing quality**:\n",
    "1. **Readability Scores**: Which version reads more clearly or is closer to the target audience?\n",
    "2. **Lexical Richness**: Does the accepted version use more domain-specific, impactful language?\n",
    "3. **Passive vs. Active Voice**: Better engagement and clarity in accepted paper?\n",
    "\n",
    "Finnally, we asked to check **review comments** to see if it was possible to align reviewer comments with specific parts of the paper to identify:\n",
    "* Common criticism themes\n",
    "*  Specific fixes that led to acceptance\n",
    "*  Overlooked suggestions in the rejected version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C93q94VkeITp"
   },
   "source": [
    "Let's see an example of the output:\n",
    "\n",
    "## Model output on: Relational Learning with Variational Bayes\n",
    "### Abstract Comparison\n",
    "Clarity, Structure, and Emphasis\n",
    "1. **Accepted version**: More polished, better flow, and uses formal transitions between ideas. Immediately connects relational learning to human cognition and AI significance before presenting the method.\n",
    "2. **Rejected version**: Conveys similar content but lacks tight phrasing and structural polish. Phrases like \"we propose an unsupervised learning method...\" feel less guided.\n",
    "\n",
    "Keywords/Framing\n",
    "1. **Accepted**: Introduces “unsupervised,” “probabilistic graphical model,” and “relational processing tasks” with more authoritative framing.\n",
    "2. **Summary**: Accepted version is stronger due to better balance between domain motivation and technical contribution. Rejected version reads more like an early draft.\n",
    "\n",
    "\n",
    "### Introduction & Motivation\n",
    "\n",
    "Problem Statement Clarity\n",
    "1. **Accepted**: Provides a crisp, formal definition (APA citation), concrete example (circles and squares), and contrasts psychological vs. ML definitions early.\n",
    "2. **Rejected**: Uses similar content but lacks clear transitions and doesn’t make the gap in current ML methods explicit early on.\n",
    "\n",
    "Novelty & Significance\n",
    "1. **Accepted**: Clearly states that current ML methods often rely on absolute properties and highlights this work as filling a critical gap.\n",
    "2. **Rejected**: Mentions novelty but less convincingly, and doesn't emphasize what’s missing in existing approaches.\n",
    "\n",
    "\n",
    "### Related Work\n",
    "\n",
    "Coverage and Currency\n",
    "1. **Accepted**: Rich discussion of supervised relational learning, SRL methods, cognitive tasks, and unsupervised disentanglement. Uses more recent and varied citations.\n",
    "2. **Rejected**: Shares many citations with the accepted version but lacks deep discussion of how existing methods fall short on decoupled relational learning.\n",
    "\n",
    "Positioning\n",
    "1. **Accepted**: Clearly positions the contribution at the intersection of PGM and unsupervised relational representation. Better differentiates from neural relational inference and disentangled learning.\n",
    "2. **Rejected**: Less effective at articulating the unique niche of the work.\n",
    "\n",
    "\n",
    "### Methodology & Experiments\n",
    "\n",
    "Clarity and Reproducibility\n",
    "1. **Accepted**: Details assumptions on latent variables, ELBO training, independence constraints, and introduces RPDA (relation-preserving data augmentation) as a novel regularization.\n",
    "2. **Rejected**: Contains same VRL core but fewer diagrams, lacks mutual information terms, and discusses optimization issues less rigorously.\n",
    "\n",
    "Visualization & Experiment Depth\n",
    "1. **Accepted**: Uses multiple datasets (MNIST, Omniglot, Yale Faces, RAVDESS). Includes comparisons against baselines and ablation studies.\n",
    "2. **Rejected**: Only presents a synthetic MNIST-based experiment with qualitative results and limited testing.\n",
    "\n",
    "### Results & Discussion\n",
    "\n",
    "Statistical Rigor\n",
    "1. **Accepted**: Reports clustering accuracy, error bars, multiple trials, and ablation studies to assess RPDA and latent design choices.\n",
    "2. **Rejected**: Primarily qualitative figures with minimal quantitative evaluation and no ablation analysis.\n",
    "\n",
    "Interpretation & Anticipating Criticism\n",
    "1. **Accepted**: Addresses overfitting, shortcut path issues, and provides mitigation strategies. Discusses failure cases explicitly.\n",
    "2. **Rejected**: Acknowledges optimization concerns but doesn’t propose solutions in depth.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Highlighting Contributions & Future Work\n",
    "1. **Accepted**: Stresses contributions in disentangling relational and absolute features, real-world applications, and even philosophical boundaries (e.g., VRL’s blindness to coupling).\n",
    "2. **Rejected**: Lists contributions but lacks foresight and clarity in summarizing future directions.\n",
    "\n",
    "---\n",
    "\n",
    "### Quantitative & Structural Insights\n",
    "\n",
    "Length Analysis\n",
    "1. **Accepted**: More detailed in methodology, related work, and experiments.\n",
    "2. **Rejected**: Shorter in scope and omits extended discussions (e.g., RPDA or variational lower bounds).\n",
    "\n",
    "Figure/Table Use\n",
    "1. **Accepted**: Includes scatter plots, reconstructions, relational mappings, ablation diagrams, and a comprehensive result table (12+ methods).\n",
    "2. **Rejected**: Fewer visuals, no baselines, and lacks ablation support.\n",
    "\n",
    "Citation Density\n",
    "1. **Accepted**: Denser and more modern references (e.g., InfoGAN, NRI, RPDA, contrastive learning).\n",
    "2. **Rejected**: Sparse citations and lacks key modern references (e.g., BYOL, vector arithmetic).\n",
    "\n",
    "---\n",
    "\n",
    "### Style and Writing Quality\n",
    "\n",
    "Readability\n",
    "1. **Accepted**: Clear, concise, and professionally written. Technical terms are introduced smoothly.\n",
    "2. **Rejected**: Wordy with awkward phrasing. Needs more editorial polish.\n",
    "\n",
    "Lexical Richness\n",
    "1. **Accepted**: Uses precise domain-specific terminology (e.g., “mutual information regularization,” “non-identifiability”).\n",
    "2. **Rejected**: Relies on general or repetitive language.\n",
    "\n",
    "Passive vs. Active Voice\n",
    "1. **Accepted**: More active constructions (“We propose...”, “Our contribution is...”) lead to stronger engagement.\n",
    "2. **Rejected**: More passive language (“is proposed”), which weakens impact.\n",
    "\n",
    "---\n",
    "\n",
    "### Review Comments (Inferred from Revisions)\n",
    "\n",
    "Common Criticism Themes (Implied)\n",
    "- Insufficient evaluation and lack of comprehensive testing.\n",
    "- Missing mitigation strategies for known issues (e.g., shortcut path, coupling).\n",
    "- Reduced clarity and reproducibility due to sparse technical detail.\n",
    "\n",
    "Specific Fixes That Led to Acceptance\n",
    "- Introduction of RPDA.\n",
    "- Mutual information penalty to enforce latent independence.\n",
    "- Expanded experiments (more datasets, baseline comparisons, quantitative metrics).\n",
    "- Better structured and clearer presentation.\n",
    "\n",
    "Overlooked Suggestions in Rejected Version\n",
    "- Full disentanglement of latent variables (z and b), acknowledged as an ongoing limitation.\n",
    "- Inclusion of real-world data evaluations.\n",
    "- Use of baseline models for comparison.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDovf4RfyTaC"
   },
   "source": [
    "## Collected Results\n",
    "\n",
    "We repeated the same questions for each of the pair of papers. This allowed us to extract more specific information about the reviewed papers, allowing for a fine-grain analysis.\n",
    "\n",
    "We then instructed the model to aggregate relevant comparative studies, distill key patterns, and generate evidence-based recommendations for improving paper quality.\n",
    "\n",
    "---\n",
    "\n",
    "Based on the reviews and comparisons of accepted and rejected papers in your dataset, here are several actionable insights for improving paper acceptance odds, along with evidence from the documents:\n",
    "\n",
    "#### Clear and Substantial Empirical Evidence Matters\n",
    "\n",
    "* Accepted papers tend to provide **comprehensive empirical evaluations** with statistically significant improvements over baselines. For instance, the accepted ASWD paper reports detailed performance benchmarks across multiple datasets and training conditions, clearly demonstrating its superiority over alternatives with metrics like FID scores and runtime evaluations\n",
    "* In contrast, the rejected version of the same work showed weaker relative improvements and lacked comparable robustness in experimental validation\n",
    "\n",
    "**Tip**: Include ablation studies, multiple datasets, and statistically sound comparisons to strengthen the empirical section.\n",
    "\n",
    "#### Well-Articulated Problem Setting and Novelty\n",
    "* Successful papers precisely define a **new, relevant problem setting**. For example, the accepted ORCA paper introduces “open-world semi-supervised learning” and distinguishes it well from adjacent concepts like zero-shot learning or open-set recognition, giving it strong novelty and motivation.\n",
    "* The rejected version lacked clarity in positioning the work as a unique contribution compared to known problems like robust SSL or novel class discovery.\n",
    "\n",
    "**Tip**: Clearly define the scope of the problem, contrast with existing work, and motivate its real-world importance.\n",
    "\n",
    "#### Strong Theoretical Backing Helps\n",
    "* Accepted papers often offer **rigorous theoretical contributions** that support empirical claims. For instance, the accepted certified robustness paper provides formal proofs and conditions for ensemble robustness using randomized smoothing.\n",
    "\n",
    "**Tip**: Where applicable, include proofs, bounds, or theoretical justifications that provide general insights beyond empirical results.\n",
    "\n",
    "#### Explainability and User Studies Add Value\n",
    "* Papers that include human-in-the-loop evaluations or explanations tend to be well-received when appropriate. The accepted explanation paper included IRB-approved user studies with clear hypotheses and statistically supported preferences from users, boosting the paper's credibility and impact.\n",
    "* The rejected version of this work lacked similarly convincing user feedback and depth in explanation evaluation.\n",
    "\n",
    "**Tip**: For human-centric tasks, complement technical work with user validation or real-world deployment data.\n",
    "\n",
    "#### Review Language Signals Quality\n",
    "In reviews, phrases often linked to acceptance include:\n",
    "* “rigorous theoretical analysis”\n",
    "* “comprehensive experiments”\n",
    "* “significantly outperforms baseline methods”\n",
    "* “clearly defines a novel problem setting”\n",
    "\n",
    "Whereas rejections often correlate with phrases like:\n",
    "* “unclear contribution”\n",
    "* “limited novelty”\n",
    "* “insufficient empirical validation”\n",
    "* “hard to follow motivation”\n",
    "\n",
    "**Tip**: Use these phrases as a litmus test: if a reviewer might not say your work “significantly outperforms baselines” or “clearly defines a novel problem,” revisit those sections.\n",
    "\n",
    "---\n",
    "\n",
    "Several **thematic trends** in the dataset suggest that certain research topics are more prone to acceptance or rejection at venues like ICLR:\n",
    "* Trendy topics like adversarial robustness and SSL still need clear novelty or real-world alignment to be accepted.\n",
    "* Cross-disciplinary ideas—especially those blending theory, application, and user interaction—appear to be favored.\n",
    "* Papers without a well-differentiated contribution, even in hot topics, are more vulnerable to rejection.\n",
    "\n",
    "---\n",
    "*From the comparative analysis on the 8 pairs of papers, can you summarize the most significant improvements among them, to give general hints to all authors?*\n",
    "\n",
    "**Substantially Strengthened Empirical Evaluation**\n",
    "\n",
    "Across almost all pairs, accepted versions introduced:\n",
    "* More datasets (e.g., CIFAR, ImageNet, MNIST variants, Minecraft).\n",
    "* More comprehensive metrics (accuracy, FID, Wasserstein distance, robustness bounds).\n",
    "* Comparison against stronger or more diverse baselines.\n",
    "* Ablation studies to isolate contributions of each component.\n",
    "\n",
    "**Hint**: Show performance across multiple settings and isolate contributions. Reviewers reward breadth and reproducibility.\n",
    "\n",
    "**Clearer Problem Framing and Novelty Positioning**.\n",
    "\n",
    "Accepted papers more explicitly:\n",
    "* Defined the problem setting and how it extends or differs from prior work.\n",
    "* Placed their contribution in context, sometimes including new terminology (e.g., “open-world semi-supervised learning”, “explanatory confidence”).\n",
    "* Clarified why the work matters, either theoretically or practically.\n",
    "\n",
    "**Hint**: Don't assume readers will infer your novelty—define it, compare it, and motivate it clearly.\n",
    "\n",
    "**Improved Theoretical Insight or Justification**\n",
    "\n",
    "For theory-heavy papers, accepted versions:\n",
    "\n",
    "* Added proof sketches or complete proofs.\n",
    "* Introduced tight bounds or conditions (e.g., certified robustness, injectivity).\n",
    "* Linked theory with design choices (e.g., why a neural mapping was injective).\n",
    "\n",
    "**Hint**: Even in application-heavy papers, theoretical grounding increases trust and interpretability.\n",
    "\n",
    "**Increased Algorithmic and Architectural Clarity**\n",
    "\n",
    "Accepted versions often added:\n",
    "\n",
    "* Pseudo-code or algorithm boxes.\n",
    "* Detailed architectural diagrams or hyperparameter setups.\n",
    "* Design rationales (why this model, loss, or initialization?).\n",
    "\n",
    "**Hint**: Help reviewers and readers reproduce or build on your work with clarity and completeness.\n",
    "\n",
    "**Inclusion of Human Studies or Real-World Use Cases (Where Applicable)**\n",
    "\n",
    "For papers involving human factors or symbolic reasoning:\n",
    "\n",
    "* Accepted versions added IRB-approved user studies, often with statistically significant findings.\n",
    "* Described deployment implications (e.g., in game AI or explainable planning).\n",
    "\n",
    "**Hint**: When humans are involved, even small-scale user feedback can validate usefulness and clarity.\n",
    "\n",
    "**Summary: Top 5 General Improvements**\n",
    "\n",
    "| Theme\t| Description |\n",
    "|---|---|\n",
    "|Stronger Experiments |\tMore datasets, metrics, ablations, baselines |\n",
    "|Clear Novelty Framing|\tExplicit differentiation from prior work; clearer motivation\n",
    "|Theoretical or Conceptual Rigor\t|Conditions, proofs, or formal assumptions that support contributions\n",
    "|Algorithm & Architecture Clarity\t|Diagrams, algorithm boxes, training details\n",
    "|Human-Centric Validation |\tUser studies, practical relevance, or task deployment results|\n",
    "\n",
    "---\n",
    "\n",
    "*From the comparative analysis on the 8 pairs of papers, can you summarize the most significant quantitative improvements among them, to give general hints to all authors?*\n",
    "\n",
    "From the comparative analysis of the 8 accepted–rejected paper pairs in your dataset, several quantitative improvements consistently contributed to acceptance. These improvements span performance metrics, experimental scope, statistical validation, and reporting clarity. Here's a synthesis of the most impactful quantitative enhancements that authors should consider:\n",
    "\n",
    "**Significantly Expanded Empirical Coverage**\n",
    "\n",
    "| Aspect |\tRejected Version |\tAccepted Version |\n",
    "|---|---|---|\n",
    "| # of Datasets\t| 1–2 |\t3–5+ (e.g., CIFAR-10, ImageNet, MNIST, Minecraft) |\n",
    "| # of Baselines |\t2–3\t| 4–6+ (including strong recent models) |\n",
    "| # of Metrics |\tAccuracy or one primary metric |\tAccuracy + FID + certified radius + runtime + uncertainty |\n",
    "\n",
    "**Hint**: Triple your experimental scope. Evaluate on more diverse datasets and metrics to demonstrate robustness.\n",
    "\n",
    "**Addition of Ablation Studies and Sensitivity Analysis**\n",
    "\n",
    "|Component\t| Rejected Version |\tAccepted Version|\n",
    "|---|---|---|\n",
    "|Ablation Studies |\tOften missing |\tPresent in all accepted versions|\n",
    "|# of Ablation Variants |\t0–2\t| 3–6+ (e.g., loss terms, architecture parts, data sizes)|\n",
    "|Hyperparameter Sensitivity\t| Rarely included |\tGrid tested (e.g., margin parameters, noise levels)|\n",
    "\n",
    "**Hint**: For every architectural or loss-function element, show its effect quantitatively.\n",
    "\n",
    "**Substantial Gains in Key Metrics Over Baselines**\n",
    "\n",
    "| Paper Domain\t| Metric |\tImprovement (Accepted vs Rejected) |\n",
    "|---|---|---|\n",
    "|Open-World SSL (ORCA) |\tAccuracy on unseen |\t+96% on ImageNet unseen classes|\n",
    "|Sliced Wasserstein Distance\t| FID in image tasks |\t10–20% better than SWD and GSWD|\n",
    "|Certified Robustness |\tCertified accuracy |\t+3–7% in L₂-radius robustness over prior SOTA|\n",
    "|Planning Explanation| \tUser task success rate |\t+35% improvement in user task performance |\n",
    "\n",
    "**Hint**: Ensure your improvements are both large in magnitude and well-justified statistically (confidence intervals, standard deviations, etc.).\n",
    "\n",
    "**Statistical Significance and Reporting Discipline**\n",
    "\n",
    "|Reporting Style\t| Rejected Version\t| Accepted Version|\n",
    "|-|-|-|\n",
    "|Standard Deviations | Sometimes omitted\t| Reported for nearly all metrics|\n",
    "|Significance Tests\t| Absent or anecdotal |\tp-values reported in user studies, comparisons|\n",
    "|Repetitions\t| 1–3 runs |\t5–10+ runs (with mean ± std)|\n",
    "\n",
    "**Hint**: Report results across multiple seeds and include statistical tests where applicable.\n",
    "\n",
    "**More Detailed Runtime and Resource Analysis**\n",
    "\n",
    "|Runtime Benchmarking |\tRejected Version\t|Accepted Version|\n",
    "|-|-|-|\n",
    "|Training Time |\tNot measured or vague |\tIncluded in tables/charts|\n",
    "|Inference Time\t| Rare |\tMeasured on multiple hardware settings|\n",
    "|Memory/Scalability |\tNot explored\t| Occasionally benchmarked|\n",
    "\n",
    "**Hint**: If your method claims scalability or practicality, quantify it in runtime or memory benchmarks.\n",
    "\n",
    "**Summary: Quantitative Improvement Targets**\n",
    "\n",
    "| Dimension |\tSuggested Target for Strong Submissions |\n",
    "|--|--|\n",
    "|# Datasets |\t≥ 3 diverse and standard datasets|\n",
    "|# Baselines |\t≥ 4, including most recent strong ones|\n",
    "|# Evaluation Metrics |\t≥ 3 (accuracy + task-specific + secondary)|\n",
    "|Ablation Studies |\t≥ 3 configurations (each with metric impact)|\n",
    "|Experimental Runs\t| ≥ 5 seeds per experiment with std reporting|\n",
    "|Metric Gains vs Baselines |\t≥ 10–20% unless margins are already tight|\n",
    "|Statistical Tests (if human)\t| p-values or confidence intervals (α = 0.05)|\n",
    "|Runtime/Memory\t| Included if efficiency is a selling point |\n",
    "\n",
    "These quantitative refinements are not only persuasive to reviewers but also signal research maturity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-VA8dC6yVp-"
   },
   "source": [
    "\n",
    "## Feedbacks on the methodology\n",
    "\n",
    "Although allowing for a fine-grain analysis, this approach has three main flaws:\n",
    "1. **time consuming**: requires to manually download each pair of papers from the openreview website.\n",
    "2. **expensive**: we are feeding the LLMs the two original PDFs for each comparative study. The input prompt with the files can vary from ~20K to ~38K tokens, while the output analysis requires ~2K tokens. We can reach around ~40K tokens, which is ~$0.44 to analyze a single paper.\n",
    "3. **data scarcity**: only a few papers in the entire dataset had both accepted and rejected versions available for download. While this smaller sample allows for fine-grained analysis, it may not be sufficient to generalize findings across the whole dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00b0bf554ca743ffbe4219bfd7e45dba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "048ce7868c974af5986d3155fc3dc3c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f26a79b20274608bc11750883402074",
       "IPY_MODEL_8e79c8b294054a6bb939a31c9c84cf78",
       "IPY_MODEL_c07ffee55de14770a4e255a36ad6df7c"
      ],
      "layout": "IPY_MODEL_dbfb7e5bcba14d189f475cd770da9e2c"
     }
    },
    "0b425aab3be847609a41d671bc88f88a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "110a93b77baf40cdacf05a75d2ac0979": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72776bf3ffc24d4a911e6266da32f3b1",
      "placeholder": "​",
      "style": "IPY_MODEL_6122ccf9ff7e45748e6011507607a27b",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "11fb86e6291f4bb08d7b2e028b179704": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18c80a054cdd4c9db8c356b541945ec7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a7838ef159641c8ad0903cbed39c1c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f26a79b20274608bc11750883402074": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cfc1707ca7a04dab85de914aa5c0e820",
      "placeholder": "​",
      "style": "IPY_MODEL_a45f98b9ab004be191aab095f38aa289",
      "value": "modules.json: 100%"
     }
    },
    "2606ac29ebf04fccad7663aaaac25fa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3cf505c9b0684fa882873c061367fdaf",
       "IPY_MODEL_75e3074cc9e74243bbc7f9326676d970",
       "IPY_MODEL_ed0bb11686664772b700136027f512db"
      ],
      "layout": "IPY_MODEL_d51dcfa5a3f2455aa6a20c9fbfb97f17"
     }
    },
    "28a7cc5b93a441138645671a2b10f7a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "291996da91cd472d915187d7075991f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29d288429c8444a282f1ae509b394fbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2bdaf76938844236a01343a4bf8a555d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6064142c22fa4bd1b2fb875e2d9c6112",
       "IPY_MODEL_2f68b2b41041484cac066d59d45df483",
       "IPY_MODEL_67afe1442fa74cd4b83c52c3b6bce88b"
      ],
      "layout": "IPY_MODEL_aab3997f84de44bb8117065d25b307a7"
     }
    },
    "2d022d11d50147488283fd7220095a1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e5ce53788bc497bb12b888cbeeb1d08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2f5b2cfabfa14223b62dea97d7ab29cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f5c2b5f8b214336a4d4f0a4d0cb1e29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d087e6ee4976478ea19d9ae4cc46f402",
      "placeholder": "​",
      "style": "IPY_MODEL_ab499233786241619560da928ba85517",
      "value": " 53.0/53.0 [00:00&lt;00:00, 4.42kB/s]"
     }
    },
    "2f68b2b41041484cac066d59d45df483": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f78bca298ed54f20b7f5c06c9310b2b1",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51cd5c18b6bd43f99526af5a91543824",
      "value": 190
     }
    },
    "2fb51d2c413a462ab9dc951331456667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e21dd1e9147e41448414301ee4f44a12",
      "max": 10454,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6918c3b2ffe448f78c0c93365d5e793f",
      "value": 10454
     }
    },
    "31044eeadda34be5acd2fa2848ead9b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "330f24c657404ab5a124feb95152b24f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fda2b299edc40a6b28d250aba1033b2",
      "placeholder": "​",
      "style": "IPY_MODEL_29d288429c8444a282f1ae509b394fbd",
      "value": " 116/116 [00:00&lt;00:00, 7.81kB/s]"
     }
    },
    "36e6083aaf10426982347290e2870536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38dd3e912cd043f89858c28255a2a9ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c29b4c3509b4f9695235b81d1590b94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3cf505c9b0684fa882873c061367fdaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7da15a52d7464079be71a2cc4dab0f22",
      "placeholder": "​",
      "style": "IPY_MODEL_9473f8faf298467391f24a24d39601e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "405c0299c23145dd8c6f7fe790ebdba2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bab84a600c894c54a51bc370752a5c63",
       "IPY_MODEL_6ea4269dc8e5440da5752eeecfd07afc",
       "IPY_MODEL_2f5c2b5f8b214336a4d4f0a4d0cb1e29"
      ],
      "layout": "IPY_MODEL_ce164f6b37934b6bacccc0bb0a9f2868"
     }
    },
    "4836b857974f42079a546ed8bcfa5db6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_487b2e6ab9cb48afb22fb603a2311971",
      "placeholder": "​",
      "style": "IPY_MODEL_38dd3e912cd043f89858c28255a2a9ae",
      "value": "config_sentence_transformers.json: 100%"
     }
    },
    "487b2e6ab9cb48afb22fb603a2311971": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "493fef8158f84a55a4e7bf220508ca9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8ca1935a9224d899815abb610be4fa5",
      "placeholder": "​",
      "style": "IPY_MODEL_69e48c4b130f4060851c77038ff2d4a7",
      "value": " 10.5k/10.5k [00:00&lt;00:00, 839kB/s]"
     }
    },
    "4aeaea4ef6e54474ba88238a1769200c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_110a93b77baf40cdacf05a75d2ac0979",
       "IPY_MODEL_69818a32d73a470ab2b4b687c11cc73d",
       "IPY_MODEL_97f306ea17494df3a61ad053027d7931"
      ],
      "layout": "IPY_MODEL_7d1425ac93914b228c21a3dfeaf9089f"
     }
    },
    "4b744854f86c4cf78e18d7224d719412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fbb028a97dd14f7290f72693e66b4dfa",
       "IPY_MODEL_d82e074d3fcc4944af1619ba24525b9b",
       "IPY_MODEL_e005fc7e5b424b90969e2e8890d443e9"
      ],
      "layout": "IPY_MODEL_5c3d126ec27344a7b96f2df3e659f8d6"
     }
    },
    "4fe644c130b94f4fb63fa274c8fc8e81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5132a3a10adb4e4faaadefb3a6a5f68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51cd5c18b6bd43f99526af5a91543824": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "521a8bcdc4f24bbbb285cef883c0c05c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56ddbec5d4a54c31b39c184f29e8e84e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c3d126ec27344a7b96f2df3e659f8d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f6573f557e64f87837b578391ee9005": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acb8bb2bc2e249588afd98d5258d742c",
       "IPY_MODEL_a60c75655a9f44f29fa48d33e7898097",
       "IPY_MODEL_7c6649231e0242adb3ef421ac592d833"
      ],
      "layout": "IPY_MODEL_a4d033b32a324f63b6cd58e28a96dcca"
     }
    },
    "6064142c22fa4bd1b2fb875e2d9c6112": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11fb86e6291f4bb08d7b2e028b179704",
      "placeholder": "​",
      "style": "IPY_MODEL_3c29b4c3509b4f9695235b81d1590b94",
      "value": "config.json: 100%"
     }
    },
    "6122ccf9ff7e45748e6011507607a27b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62242c89ac7a41d9b72aa86f31c4ca42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67afe1442fa74cd4b83c52c3b6bce88b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00b0bf554ca743ffbe4219bfd7e45dba",
      "placeholder": "​",
      "style": "IPY_MODEL_f6203d914ead4b3aac7acd508a4e4171",
      "value": " 190/190 [00:00&lt;00:00, 7.87kB/s]"
     }
    },
    "6816300cbefa4bacaef4bd6c1816d983": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6918c3b2ffe448f78c0c93365d5e793f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69818a32d73a470ab2b4b687c11cc73d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1f90fec3e43413691aab054b51ad214",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_761c294f135d48208a7d680df4b24181",
      "value": 112
     }
    },
    "69e48c4b130f4060851c77038ff2d4a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c52a219b9a043359f45d7203cbcd45d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ea4269dc8e5440da5752eeecfd07afc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6d812bffb044b029758929fc2416016",
      "max": 53,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f56334915ae24d7b96d76e7637b0b3fc",
      "value": 53
     }
    },
    "6f80cf1648654813a9f5b2c1c23e8f6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72776bf3ffc24d4a911e6266da32f3b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "744993ca399a4e5581e649bb34b64db3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75e3074cc9e74243bbc7f9326676d970": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fe644c130b94f4fb63fa274c8fc8e81",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_28a7cc5b93a441138645671a2b10f7a6",
      "value": 350
     }
    },
    "761c294f135d48208a7d680df4b24181": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77b09b2b6f32419ab56c9e9b4fb3b6f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af5e52197f4147eba3cec62892e89d5f",
      "max": 466247,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b70f89abe3f94a7f846e9bde461be332",
      "value": 466247
     }
    },
    "7c6649231e0242adb3ef421ac592d833": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f80cf1648654813a9f5b2c1c23e8f6d",
      "placeholder": "​",
      "style": "IPY_MODEL_ede1351bae8147da9a299a7cb1a36518",
      "value": " 232k/232k [00:00&lt;00:00, 4.63MB/s]"
     }
    },
    "7d1425ac93914b228c21a3dfeaf9089f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7da15a52d7464079be71a2cc4dab0f22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "820f19d9c6e24bf78a6a4beb46b26968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6816300cbefa4bacaef4bd6c1816d983",
      "placeholder": "​",
      "style": "IPY_MODEL_fe89757f6605465dbea0e90e140416fe",
      "value": "config.json: 100%"
     }
    },
    "848ed9836179439593070e7b7e2ee501": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8dd5e29c16874004840d3c47c27fff0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8e79c8b294054a6bb939a31c9c84cf78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c89208694aee494491928a5c9610b01a",
      "max": 349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d022d11d50147488283fd7220095a1a",
      "value": 349
     }
    },
    "8fda2b299edc40a6b28d250aba1033b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9473f8faf298467391f24a24d39601e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "95561c0d72e0423b910bb0b4aeeae110": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a84e4d15535f46719241c7a0b45b3ac8",
      "max": 612,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e5ce53788bc497bb12b888cbeeb1d08",
      "value": 612
     }
    },
    "97f306ea17494df3a61ad053027d7931": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_291996da91cd472d915187d7075991f5",
      "placeholder": "​",
      "style": "IPY_MODEL_36e6083aaf10426982347290e2870536",
      "value": " 112/112 [00:00&lt;00:00, 4.33kB/s]"
     }
    },
    "98d8dcb86e874441ac06bca3f47cdd9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c909c1bacad421486a9059e7e3daf00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_820f19d9c6e24bf78a6a4beb46b26968",
       "IPY_MODEL_95561c0d72e0423b910bb0b4aeeae110",
       "IPY_MODEL_ab9364587b1e4f8bbaefb909f5b8d013"
      ],
      "layout": "IPY_MODEL_18c80a054cdd4c9db8c356b541945ec7"
     }
    },
    "a0c2de45dbcc4aae80e94caaecedc094": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a15f8c9982cc4fb591fa3ac64108c84b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1d88b678278467c892bf9870670091b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a45f98b9ab004be191aab095f38aa289": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4d033b32a324f63b6cd58e28a96dcca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a60c75655a9f44f29fa48d33e7898097": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c52a8b0beb8b4a37b5bbba4e5438c93f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8beff6271de40058675e3794662c83c",
      "value": 231508
     }
    },
    "a84e4d15535f46719241c7a0b45b3ac8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8beff6271de40058675e3794662c83c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aab3997f84de44bb8117065d25b307a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab499233786241619560da928ba85517": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab9364587b1e4f8bbaefb909f5b8d013": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56ddbec5d4a54c31b39c184f29e8e84e",
      "placeholder": "​",
      "style": "IPY_MODEL_fb337ec946cf4fb489608c4743e222dc",
      "value": " 612/612 [00:00&lt;00:00, 50.9kB/s]"
     }
    },
    "acb8bb2bc2e249588afd98d5258d742c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_beac4858fdff4c2e9cb81728465a80fc",
      "placeholder": "​",
      "style": "IPY_MODEL_744993ca399a4e5581e649bb34b64db3",
      "value": "vocab.txt: 100%"
     }
    },
    "af5e52197f4147eba3cec62892e89d5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5f26b28b96345f5bf90f7833cacb4d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbac9cfb7c244fdfaebd7dfbce477ee2",
      "placeholder": "​",
      "style": "IPY_MODEL_98d8dcb86e874441ac06bca3f47cdd9f",
      "value": "README.md: 100%"
     }
    },
    "b70f89abe3f94a7f846e9bde461be332": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b8ca1935a9224d899815abb610be4fa5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bab84a600c894c54a51bc370752a5c63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c52a219b9a043359f45d7203cbcd45d",
      "placeholder": "​",
      "style": "IPY_MODEL_a1d88b678278467c892bf9870670091b",
      "value": "sentence_bert_config.json: 100%"
     }
    },
    "bc96b2e2dc6f4afba610555e62067159": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf8c4ac65e5c490089423fa4f36af466",
       "IPY_MODEL_77b09b2b6f32419ab56c9e9b4fb3b6f7",
       "IPY_MODEL_c8dfec8c73c146a09200c960f306f87e"
      ],
      "layout": "IPY_MODEL_bd2f5f05bf7a4e9ca33654af0a46c76a"
     }
    },
    "bd2f5f05bf7a4e9ca33654af0a46c76a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be2e1b57b4eb483aa2a60daa20aff685": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "beac4858fdff4c2e9cb81728465a80fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf8c4ac65e5c490089423fa4f36af466": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be2e1b57b4eb483aa2a60daa20aff685",
      "placeholder": "​",
      "style": "IPY_MODEL_c135f68322554d259bdfdabf91f88950",
      "value": "tokenizer.json: 100%"
     }
    },
    "c07ffee55de14770a4e255a36ad6df7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b425aab3be847609a41d671bc88f88a",
      "placeholder": "​",
      "style": "IPY_MODEL_848ed9836179439593070e7b7e2ee501",
      "value": " 349/349 [00:00&lt;00:00, 29.8kB/s]"
     }
    },
    "c135f68322554d259bdfdabf91f88950": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1a189a73b3447d2be3fa757a5f9517f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1f90fec3e43413691aab054b51ad214": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c46e405354fd4a609780ee396c1f8e5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c52a8b0beb8b4a37b5bbba4e5438c93f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c89208694aee494491928a5c9610b01a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8dfec8c73c146a09200c960f306f87e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31044eeadda34be5acd2fa2848ead9b3",
      "placeholder": "​",
      "style": "IPY_MODEL_e6ee55e082fd4c2a8f868f88e3735c1f",
      "value": " 466k/466k [00:00&lt;00:00, 19.9MB/s]"
     }
    },
    "ce164f6b37934b6bacccc0bb0a9f2868": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfc1707ca7a04dab85de914aa5c0e820": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d087e6ee4976478ea19d9ae4cc46f402": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d50cbb22bacc44d9bf9c19848cb788a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f5b2cfabfa14223b62dea97d7ab29cf",
      "max": 116,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f35b7bca7ea74703af41991ca9089e11",
      "value": 116
     }
    },
    "d51dcfa5a3f2455aa6a20c9fbfb97f17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d82e074d3fcc4944af1619ba24525b9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1a189a73b3447d2be3fa757a5f9517f",
      "max": 90868376,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8dd5e29c16874004840d3c47c27fff0c",
      "value": 90868376
     }
    },
    "dbfb7e5bcba14d189f475cd770da9e2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e005fc7e5b424b90969e2e8890d443e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62242c89ac7a41d9b72aa86f31c4ca42",
      "placeholder": "​",
      "style": "IPY_MODEL_1a7838ef159641c8ad0903cbed39c1c5",
      "value": " 90.9M/90.9M [00:00&lt;00:00, 168MB/s]"
     }
    },
    "e21dd1e9147e41448414301ee4f44a12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6d812bffb044b029758929fc2416016": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6ee55e082fd4c2a8f868f88e3735c1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8009ac969134d3783c3c8f04fca2ba9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b5f26b28b96345f5bf90f7833cacb4d0",
       "IPY_MODEL_2fb51d2c413a462ab9dc951331456667",
       "IPY_MODEL_493fef8158f84a55a4e7bf220508ca9d"
      ],
      "layout": "IPY_MODEL_521a8bcdc4f24bbbb285cef883c0c05c"
     }
    },
    "e97d704291b243d584735afc4dc5398e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4836b857974f42079a546ed8bcfa5db6",
       "IPY_MODEL_d50cbb22bacc44d9bf9c19848cb788a7",
       "IPY_MODEL_330f24c657404ab5a124feb95152b24f"
      ],
      "layout": "IPY_MODEL_c46e405354fd4a609780ee396c1f8e5f"
     }
    },
    "ed0bb11686664772b700136027f512db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0c2de45dbcc4aae80e94caaecedc094",
      "placeholder": "​",
      "style": "IPY_MODEL_f2e99bc18ff444b4b7e8a183d720be15",
      "value": " 350/350 [00:00&lt;00:00, 17.9kB/s]"
     }
    },
    "ede1351bae8147da9a299a7cb1a36518": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2e99bc18ff444b4b7e8a183d720be15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f35b7bca7ea74703af41991ca9089e11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f56334915ae24d7b96d76e7637b0b3fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6203d914ead4b3aac7acd508a4e4171": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f78bca298ed54f20b7f5c06c9310b2b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb337ec946cf4fb489608c4743e222dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbac9cfb7c244fdfaebd7dfbce477ee2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbb028a97dd14f7290f72693e66b4dfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a15f8c9982cc4fb591fa3ac64108c84b",
      "placeholder": "​",
      "style": "IPY_MODEL_5132a3a10adb4e4faaadefb3a6a5f68d",
      "value": "model.safetensors: 100%"
     }
    },
    "fe89757f6605465dbea0e90e140416fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
